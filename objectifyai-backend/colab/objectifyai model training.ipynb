{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-13T10:59:16.962670Z",
     "iopub.status.busy": "2025-03-13T10:59:16.962347Z",
     "iopub.status.idle": "2025-03-13T10:59:24.687328Z",
     "shell.execute_reply": "2025-03-13T10:59:24.686101Z",
     "shell.execute_reply.started": "2025-03-13T10:59:16.962644Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (4.9.7)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.2.1)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (5.9.5)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (19.0.1)\n",
      "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.6)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.13.1)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.67.1)\n",
      "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.5.1)\n",
      "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (1.11.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (2024.12.0)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (5.13.0)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (3.21.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.66.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
      "Num GPUs Available: 2\n",
      "✅ GPU is available!\n",
      "Number of devices: 2\n",
      "tfds.core.DatasetInfo(\n",
      "    name='coco',\n",
      "    full_name='coco/2017/1.1.0',\n",
      "    description=\"\"\"\n",
      "    COCO is a large-scale object detection, segmentation, and\n",
      "    captioning dataset.\n",
      "    \n",
      "    Note:\n",
      "     * Some images from the train and validation sets don't have annotations.\n",
      "     * Coco 2014 and 2017 uses the same images, but different train/val/test splits\n",
      "     * The test split don't have any annotations (only images).\n",
      "     * Coco defines 91 classes but the data only uses 80 classes.\n",
      "     * Panotptic annotations defines defines 200 classes but only uses 133.\n",
      "    \"\"\",\n",
      "    config_description=\"\"\"\n",
      "    \n",
      "    This version contains images, bounding boxes and labels for the 2017 version.\n",
      "    \n",
      "    \"\"\",\n",
      "    homepage='http://cocodataset.org/#home',\n",
      "    data_dir='/root/tensorflow_datasets/coco/2017/1.1.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=25.20 GiB,\n",
      "    dataset_size=24.98 GiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
      "        'image/filename': Text(shape=(), dtype=string),\n",
      "        'image/id': int64,\n",
      "        'objects': Sequence({\n",
      "            'area': int64,\n",
      "            'bbox': BBoxFeature(shape=(4,), dtype=float32),\n",
      "            'id': int64,\n",
      "            'is_crowd': bool,\n",
      "            'label': ClassLabel(shape=(), dtype=int64, num_classes=80),\n",
      "        }),\n",
      "    }),\n",
      "    supervised_keys=None,\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=40670, num_shards=64>,\n",
      "        'train': <SplitInfo num_examples=118287, num_shards=256>,\n",
      "        'validation': <SplitInfo num_examples=5000, num_shards=8>,\n",
      "    },\n",
      "    citation=\"\"\"@article{DBLP:journals/corr/LinMBHPRDZ14,\n",
      "      author    = {Tsung{-}Yi Lin and\n",
      "                   Michael Maire and\n",
      "                   Serge J. Belongie and\n",
      "                   Lubomir D. Bourdev and\n",
      "                   Ross B. Girshick and\n",
      "                   James Hays and\n",
      "                   Pietro Perona and\n",
      "                   Deva Ramanan and\n",
      "                   Piotr Doll{'{a}}r and\n",
      "                   C. Lawrence Zitnick},\n",
      "      title     = {Microsoft {COCO:} Common Objects in Context},\n",
      "      journal   = {CoRR},\n",
      "      volume    = {abs/1405.0312},\n",
      "      year      = {2014},\n",
      "      url       = {http://arxiv.org/abs/1405.0312},\n",
      "      archivePrefix = {arXiv},\n",
      "      eprint    = {1405.0312},\n",
      "      timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},\n",
      "      biburl    = {https://dblp.org/rec/bib/journals/corr/LinMBHPRDZ14},\n",
      "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
      "    }\"\"\",\n",
      ")\n",
      "Number of classes: 80\n",
      "Image min: 0.0\n",
      "Image max: 1.0\n",
      "Label min: 0.0\n",
      "Label max: 1.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sequential model 'sequential_4' has no defined input shape yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cd54a6be7cb0>\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;31m# Custom Model with Regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     model = models.Sequential([\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# MobileNetV2 Base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, trainable, name)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrebuild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_rebuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrebuild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36m_maybe_rebuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_shape\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;31m# We can build the Sequential model if the first layer has the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# `input_shape` property. This is most commonly found in Functional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36minput_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0;34mf\"Sequential model '{self.name}' has no defined input shape yet.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Sequential model 'sequential_4' has no defined input shape yet."
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install tensorflow opencv-python tensorflow-datasets\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Check GPU Availability\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available:\", len(gpus))\n",
    "if gpus:\n",
    "    print(\"✅ GPU is available!\")\n",
    "    tf.config.optimizer.set_jit(True)  # Enable XLA Compilation\n",
    "else:\n",
    "    print(\"❌ GPU is NOT available. Using CPU.\")\n",
    "\n",
    "# Enable Mixed Precision for Speed Boost\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "# Define Multi-GPU Strategy\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n",
    "\n",
    "# Load COCO dataset once with both 'train' and 'validation' splits\n",
    "datasets, info = tfds.load('coco/2017', with_info=True, split=['train', 'validation'])\n",
    "\n",
    "# Assign train and validation datasets separately\n",
    "dataset, test_dataset = datasets\n",
    "\n",
    "# Print dataset info\n",
    "print(info)\n",
    "\n",
    "# Define num_classes\n",
    "num_classes = info.features['objects']['label'].num_classes\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Data Preprocessing Function\n",
    "def preprocess_data(data):\n",
    "    image = tf.image.resize(data['image'], (128, 128))  # Resize images\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize\n",
    "\n",
    "    labels = data['objects']['label']\n",
    "    labels = tf.one_hot(labels, depth=num_classes)  # One-hot encode labels\n",
    "    labels = tf.reduce_max(labels, axis=0)  # Convert to multi-hot encoding\n",
    "\n",
    "    # Ensure no NaN or Inf values\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    labels = tf.clip_by_value(labels, 0.0, 1.0)\n",
    "\n",
    "    return image, labels\n",
    "\n",
    "# Prepare dataset\n",
    "batch_size = 32 * strategy.num_replicas_in_sync  # Scale batch size by number of GPUs\n",
    "train_data = dataset.map(preprocess_data).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "test_data = test_dataset.map(preprocess_data).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Check Sample Data\n",
    "for image, label in train_data.take(1):\n",
    "    print(\"Image min:\", tf.reduce_min(image).numpy())\n",
    "    print(\"Image max:\", tf.reduce_max(image).numpy())\n",
    "    print(\"Label min:\", tf.reduce_min(label).numpy())\n",
    "    print(\"Label max:\", tf.reduce_max(label).numpy())\n",
    "\n",
    "# Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "# Define and Compile the Model within the Strategy Scope\n",
    "with strategy.scope():\n",
    "    # Load MobileNetV2 as Base Model\n",
    "    base_model = MobileNetV2(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False  # Freeze the base model initially\n",
    "\n",
    "    # Custom Model with Regularization\n",
    "    model = models.Sequential([\n",
    "        data_augmentation,\n",
    "        base_model,  # MobileNetV2 Base\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Force model to build\n",
    "    model.build(input_shape=(None, 128, 128, 3))\n",
    "\n",
    "    # Learning Rate Scheduler\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "    # Compile the Model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001, clipnorm=1.0),  # Gradient clipping\n",
    "                 loss='binary_crossentropy',  # Binary cross-entropy for multi-label classification\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Fine-tune the Model (Unfreeze Last Layers)\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:  # Keep first layers frozen\n",
    "    layer.trainable = False\n",
    "\n",
    "# Train the Model\n",
    "epochs = 8\n",
    "history = model.fit(train_data, epochs=epochs, validation_data=test_data, callbacks=[lr_scheduler])\n",
    "\n",
    "# Evaluate the Model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "if np.isnan(test_loss):  # Fix NaN issue\n",
    "    test_loss = 0.0\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Save the Model\n",
    "model.save(\"object_recognition_model1.keras\")\n",
    "\n",
    "# Extract class labels from dataset info\n",
    "class_names = info.features['objects']['label'].names\n",
    "\n",
    "# Save class labels\n",
    "np.save(\"classes.npy\", class_names)\n",
    "print(\"Class names saved successfully!\")\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Check GPU Usage\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:11:23.003549Z",
     "iopub.status.busy": "2025-03-13T05:11:23.003229Z",
     "iopub.status.idle": "2025-03-13T05:36:46.480605Z",
     "shell.execute_reply": "2025-03-13T05:36:46.479719Z",
     "shell.execute_reply.started": "2025-03-13T05:11:23.003523Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ mobilenetv2_1.00_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,040</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ mobilenetv2_1.00_128 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m655,872\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  │          \u001b[38;5;34m41,040\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,954,896</span> (11.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,954,896\u001b[0m (11.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">696,912</span> (2.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m696,912\u001b[0m (2.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m1849/1849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 104ms/step - accuracy: 0.5288 - loss: 0.5368 - val_accuracy: 0.5300 - val_loss: 0.1217 - learning_rate: 0.0010\n",
      "Epoch 2/8\n",
      "\u001b[1m1849/1849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 105ms/step - accuracy: 0.5712 - loss: 0.1136 - val_accuracy: 0.5580 - val_loss: 0.1171 - learning_rate: 0.0010\n",
      "Epoch 3/8\n",
      "\u001b[1m1849/1849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 100ms/step - accuracy: 0.5773 - loss: 0.1091 - val_accuracy: 0.6188 - val_loss: 0.1040 - learning_rate: 0.0010\n",
      "Epoch 4/8\n",
      "\u001b[1m1849/1849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 100ms/step - accuracy: 0.5830 - loss: 0.1057 - val_accuracy: 0.6158 - val_loss: 0.1029 - learning_rate: 0.0010\n",
      "Epoch 5/8\n",
      "\u001b[1m1849/1849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 99ms/step - accuracy: 0.5866 - loss: 0.1034 - val_accuracy: 0.5620 - val_loss: 0.1007 - learning_rate: 0.0010\n",
      "Epoch 6/8\n",
      "\u001b[1m1849/1849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 99ms/step - accuracy: 0.5899 - loss: 0.1018 - val_accuracy: 0.5752 - val_loss: 0.1034 - learning_rate: 0.0010\n",
      "Epoch 7/8\n",
      "\u001b[1m1849/1849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 99ms/step - accuracy: 0.5918 - loss: 0.1004 - val_accuracy: 0.5970 - val_loss: 0.0956 - learning_rate: 0.0010\n",
      "Epoch 8/8\n",
      "\u001b[1m1849/1849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 99ms/step - accuracy: 0.5960 - loss: 0.0988 - val_accuracy: 0.5944 - val_loss: 0.0973 - learning_rate: 0.0010\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5964 - loss: 0.0972\n",
      "Test Accuracy: 59.44%\n",
      "Test Loss: 0.0973\n",
      "Class names saved successfully!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABw00lEQVR4nO3dd3hUddrG8e+k9xAS0iAklEDoYCgCAioofZUVAVcFBGV1QVHEVSwLiopdVtcXLBQ7lhWlCIigKCBLk6L0HkoaJZW0mXn/OGQgECCBJCfJ3J/rOldOppx5BmPmzq9a7Ha7HREREREn4mJ2ASIiIiIVTQFIREREnI4CkIiIiDgdBSARERFxOgpAIiIi4nQUgERERMTpKACJiIiI03Ezu4DKyGazcfToUfz9/bFYLGaXIyIiIiVgt9vJyMggMjISF5dLt/EoABXj6NGjREVFmV2GiIiIXIGEhATq1KlzyccoABXD398fMP4BAwICTK5GRERESiI9PZ2oqCjH5/ilKAAVo7DbKyAgQAFIRESkiinJ8BUNghYRERGnowAkIiIiTkcBSERERJyOxgCJiEi5sdls5OXlmV2GVBPu7u64urqWybUUgEREpFzk5eWxf/9+bDab2aVINVKjRg3Cw8Ovep0+BSARESlzdrudY8eO4erqSlRU1GUXpRO5HLvdTnZ2NsnJyQBERERc1fVMD0DvvPMOr776KomJibRq1Yq3336b9u3bX/Txp06d4qmnnuKbb77hxIkTREdHM3XqVPr06QPAlClT+Oabb9ixYwfe3t506tSJl19+mcaNG1fUWxIRcXoFBQVkZ2cTGRmJj4+P2eVINeHt7Q1AcnIyoaGhV9UdZmok/+KLLxg3bhwTJ05k48aNtGrVip49ezrS3fny8vK46aabOHDgAF9//TU7d+7k/fffp3bt2o7HrFixgtGjR7NmzRqWLl1Kfn4+N998M1lZWRX1tkREnJ7VagXAw8PD5EqkuikM1Pn5+Vd1HYvdbreXRUFXokOHDrRr147//Oc/gDFYLioqigcffJAnnnjigsdPnz6dV199lR07duDu7l6i10hJSSE0NJQVK1bQtWvXYh+Tm5tLbm6u4/vClSTT0tK0EKKIyBXIyclh//791KtXDy8vL7PLkWrkUj9b6enpBAYGlujz27QWoLy8PDZs2ECPHj3OFuPiQo8ePfjtt9+Kfc68efPo2LEjo0ePJiwsjObNm/Piiy86/tIoTlpaGgA1a9a86GOmTJlCYGCg49A+YCIiItWbaQEoNTUVq9VKWFhYkdvDwsJITEws9jn79u3j66+/xmq18v333/PMM8/w+uuv8/zzzxf7eJvNxsMPP0znzp1p3rz5RWuZMGECaWlpjiMhIeHK35iIiIhUeqYPgi4Nm81GaGgo7733Hq6ursTHx3PkyBFeffVVJk6ceMHjR48ezR9//MHKlSsveV1PT088PT3Lq2wREXFiMTExPPzwwzz88MNmlyLnMK0FKCQkBFdXV5KSkorcnpSURHh4eLHPiYiIoFGjRkVGfTdp0oTExMQLFtoaM2YMCxYs4KeffqJOnTpl/wZErlROGpg39E5ELsJisVzymDRp0hVdd926dYwaNapMavz8889xdXVl9OjRZXI9Z2ZaAPLw8CA+Pp5ly5Y5brPZbCxbtoyOHTsW+5zOnTuzZ8+eIotq7dq1i4iICMdMA7vdzpgxY5g7dy7Lly+nXr165ftGREpj5ZvwUl2YEgUf3ATzH4a178OBVXD6pNnViTi1Y8eOOY6pU6cSEBBQ5Lbx48c7Hmu32ykoKCjRdWvVqlVmSwHMmDGDf/7zn3z++efk5OSUyTWvVFVf4dvUafDjxo3j/fff58MPP2T79u088MADZGVlcc899wAwdOhQJkyY4Hj8Aw88wIkTJxg7diy7du1i4cKFvPjii0WS8OjRo/nkk0/47LPP8Pf3JzExkcTERE6fPl3h70/kAps+M77mZcDhtbBhFnw/Hmb3gZdj4PUm8Mlt8MMzsHkOJG6FgtxLXlKkKrDb7WTnFZhylHSyc3h4uOMIDAzEYrE4vt+xYwf+/v4sWrSI+Ph4PD09WblyJXv37uWWW24hLCwMPz8/2rVrx48//ljkujExMUydOtXxvcVi4YMPPmDAgAH4+PgQGxvLvHnzLlvf/v37Wb16NU888QSNGjXim2++ueAxM2fOpFmzZnh6ehIREcGYMWMc9506dYq///3vhIWF4eXlRfPmzVmwYAEAkyZNonXr1kWuNXXqVGJiYhzfDx8+nFtvvZUXXniByMhIx/p6H3/8MW3btsXf35/w8HD+9re/XbCczZ9//km/fv0ICAjA39+fLl26sHfvXn755Rfc3d0vGPv78MMP06VLl8v+m1wNU8cADR48mJSUFP71r3+RmJhI69atWbx4sWNg9KFDh4qsHhoVFcWSJUt45JFHaNmyJbVr12bs2LE8/vjjjsdMmzYNgOuvv77Ia82aNYvhw4eX+3sSuaiTByF1F1hcYcQSOHkAkv+EpG2QvA3SEiDjqHHsOecXqMUVQmIhtCmENYXQZsbXwLqg1XWlijidb6Xpv5aY8trbnuuJj0fZfNw98cQTvPbaa9SvX5+goCASEhLo06cPL7zwAp6ennz00Uf079+fnTt3Urdu3Yte59lnn+WVV17h1Vdf5e233+bOO+/k4MGDl5yxPGvWLPr27UtgYCB33XUXM2bM4G9/+5vj/mnTpjFu3DheeuklevfuTVpaGqtWrQKMHpbevXuTkZHBJ598QoMGDdi2bVupFxJctmwZAQEBLF261HFbfn4+kydPpnHjxiQnJzNu3DiGDx/O999/D8CRI0fo2rUr119/PcuXLycgIIBVq1ZRUFBA165dqV+/Ph9//DGPPfaY43qffvopr7zySqlqKy3TB0GPGTOmSEI9188//3zBbR07dmTNmjUXvZ6JyxqJXNreM929Ue0hqp1xcPvZ+3PSIHk7JP1pHMnbjHCUmwYpO4zjz3P+4vPwg9AmENbsbCgKbQo+F/8FKiJX57nnnuOmm25yfF+zZk1atWrl+H7y5MnMnTuXefPmXfSzDYzWlDvuuAOAF198kbfeeou1a9fSq1evYh9vs9mYPXs2b7/9NgBDhgzh0UcfdayHA/D888/z6KOPMnbsWMfz2rVrB8CPP/7I2rVr2b59O40aNQKgfv36pX7/vr6+fPDBB0UWuBwxYoTjvH79+rz11lu0a9eOzMxM/Pz8eOeddwgMDGTOnDmONfwKawAYOXIks2bNcgSg+fPnk5OTw6BBg0pdX2mYHoBEnMaeMwGoQffi7/cKhLrXGkchux3Sj5xpJTqntShlJ+RlwuF1xnEu/4gLW4tCGoO7FqMT83i7u7LtuZ6mvXZZadu2bZHvMzMzmTRpEgsXLuTYsWMUFBRw+vRpDh06dMnrtGzZ0nHu6+tLQEDARXdBAFi6dClZWVmObZ9CQkK46aabmDlzJpMnTyY5OZmjR4/SvXvxv182bdpEnTp1igSPK9GiRYsLVvfesGEDkyZNYvPmzZw8edIxTvfQoUM0bdqUTZs20aVLl4suYDx8+HCefvpp1qxZw7XXXsvs2bMZNGgQvr6+V1Xr5SgAiVQEaz7sW2GcN7xIACqOxQKBdYyj0c1Fr5e6+0wr0TmtRWmHIOOYcexdds51XCG4YdFQFNoUakSrG00qhMViKbNuKDOd/6E8fvx4li5dymuvvUbDhg3x9vZm4MCBlx0gfH4YsFgsRSb4nG/GjBmcOHHCsRcWGK1CW7Zs4dlnny1ye3Eud7+Li8sFPSjFbTVx/vvPysqiZ8+e9OzZk08//ZRatWpx6NAhevbs6fg3uNxrh4aG0r9/f2bNmkW9evVYtGhRsT1AZa3q/zSKVAUJa42Bzz7BENH66q/n6m6EmLCm0GLg2dtz0o1utOQz3WiFLUc5aZC60zj+nHv28R5+UCvO6EYLa3am5aiZutFESmjVqlUMHz6cAQMGAEaL0IEDB8r0NY4fP853333HnDlzaNasmeN2q9XKddddxw8//ECvXr2IiYlh2bJl3HDDDRdco2XLlhw+fJhdu3YV2wpUq1YtEhMTsdvtWCwWwGg1upwdO3Zw/PhxXnrpJccuCuvXr7/gtT/88EPy8/Mv2gp07733cscdd1CnTh0aNGhA586dL/vaV0sBSKQiFLbGNLixfFtcvAKgbgfjKGS3Q/rRC1uLUs90ox1Zbxzn8gs/20pUGIxqxakbTeQ8sbGxfPPNN/Tv3x+LxcIzzzxzyZacK/Hxxx8THBzMoEGDHOGkUJ8+fZgxYwa9evVi0qRJ3H///YSGhjoGPK9atYoHH3yQbt260bVrV2677TbeeOMNGjZsyI4dO7BYLPTq1Yvrr7+elJQUXnnlFQYOHMjixYtZtGjRZffTqlu3Lh4eHrz99tvcf//9/PHHH0yePLnIY8aMGcPbb7/NkCFDmDBhAoGBgaxZs4b27ds7ZpL17NmTgIAAnn/+eZ577rky/fe7GAUgkYpQOKurYY9LP648WCwQWNs4Ys8O3sSaD8f3FA1FyX/CqUOQmWgce5efcx1XCG5QNBSFNYUaMepGE6f1xhtvMGLECDp16kRISAiPP/446enpZfoaM2fOZMCAAReEH4DbbruNu+++m9TUVIYNG0ZOTg5vvvkm48ePJyQkhIEDz7YQ//e//2X8+PHccccdZGVl0bBhQ1566SXAWFT4//7v/3jxxReZPHkyt912G+PHj+e99967ZG21atVi9uzZPPnkk7z11ltcc801vPbaa/zlL39xPCY4OJjly5fz2GOP0a1bN1xdXWndunWRVh4XFxeGDx/Oiy++yNChQ6/2n6xETN0NvrIqzW6yIpeVmQyvxRrn43eDX6i59VxOTrox46zIbLQ/IedU8Y9394XQuDOBqPnZcUa+wRVatlQu2g1eSmvkyJGkpKRcdk2kstoNXi1AIuVt70/G1/CWlT/8gNGNFtXeOArZ7cbA6iKz0f40ZqPlZ8GRDcZxLr+wC1uLasWB+6UHRIqIc0lLS2Pr1q189tlnJVoQsqwoAImUNzO7v8qKxQIBkcYRe877sObD8b1Fp+gn/QmnDkJmknHs++mc67hAzQZw7QPQbmTFvw8RqXRuueUW1q5dy/33319kjaXypgAkUp5strMDoKtyALoYV/cz3V9x0Py2s7fnZkDyjrPBKOlP4/z0STi+29jqo/Xf1BokIhUy5b04CkAi5SlxM2QfBw//ol1K1Z2n/zmrXZ9ht0NGInzQ3Vjccd/P0Li3aSWKiHPT1A2R8lTY/VW/m9Fa4swsFgiIgLi+xvfbF5hbj4g4NQUgkfJUuP1FaVZ/ru7i+hlfd34P1gJzaxERp6UAJFJectKMFaDh4vt/OaPozuAdBKdPwKHfzK5GRJyUApBIedm3AuxWCI6FoGizq6k8XN2g0ZmxPzvUDSYi5lAAEikv1WH6e3lpcqYbbMdCY3C0SDVy/fXX8/DDD5tdhlyGApBIebDbzxn/owB0gQY3grsPpCXAsU1mVyMCQP/+/enVq1ex9/36669YLBa2bNlSZq93+vRpatasSUhICLm5uWV2XSkZBSCR8pC6C9IPg6snRHcyu5rKx9377MBwzQaTSmLkyJEsXbqUw4cPX3DfrFmzaNu2LS1btiyz1/vvf/9Ls2bNiIuL49tvvy2z614Ju91OQYFzTUpQABIpD4XdXzGdwcPH3Foqq7j+xleNA5JKol+/fo7NPc+VmZnJV199xciRIzl+/Dh33HEHtWvXxsfHhxYtWvD5559f0evNmDGDu+66i7vuuosZM2ZccP+ff/5Jv379CAgIwN/fny5durB3717H/TNnzqRZs2Z4enoSERHBmDFjADhw4AAWi4VNmzY5Hnvq1CksFotj0cGff/4Zi8XCokWLiI+Px9PTk5UrV7J3715uueUWwsLC8PPzo127dvz4449F6srNzeXxxx8nKioKT09PGjZsyIwZM7Db7TRs2JDXXnutyOM3bdqExWJhz549V/TvVF4UgETKg8b/XF6jm8HFzdh4NbVy/WKUcmC3Q16WOUcJx5m5ubkxdOhQZs+ezbn7hH/11VdYrVbuuOMOcnJyiI+PZ+HChfzxxx+MGjWKu+++m7Vr15bqn2Pv3r389ttvDBo0iEGDBvHrr79y8OBBx/1Hjhyha9eueHp6snz5cjZs2MCIESMcrTTTpk1j9OjRjBo1iq1btzJv3jwaNmxYqhoAnnjiCV566SW2b99Oy5YtyczMpE+fPixbtozff/+dXr160b9/fw4dOuR4ztChQ/n8889566232L59O++++y5+fn5YLBZGjBjBrFmzirzGrFmz6Nq16xXVV560ErRIWcs/DQdXG+ea/n5x3kEQ08XYK2zHfLjuEbMrkvKUnw0vRprz2k8eBQ/fEj10xIgRvPrqq6xYsYLrr78eMD7Ab7vtNgIDAwkMDGT8+PGOxz/44IMsWbKEL7/8kvbtS77a+8yZM+nduzdBQUEA9OzZk1mzZjFp0iQA3nnnHQIDA5kzZw7u7sYiqo0aNXI8//nnn+fRRx9l7NixjtvatTtn5fUSeu6554rsv1WzZk1atWrl+H7y5MnMnTuXefPmMWbMGHbt2sWXX37J0qVL6dHD+AOvfv36jscPHz6cf/3rX6xdu5b27duTn5/PZ599dkGrUGWgFiCRsnZgFRTkQEAdqNXY7Goqt8LZYBoHJJVEXFwcnTp1YubMmQDs2bOHX3/9lZEjjc17rVYrkydPpkWLFtSsWRM/Pz+WLFlSpIXkcqxWKx9++CF33XWX47a77rqL2bNnY7PZAKPbqEuXLo7wc67k5GSOHj1K9+5X/wdW27Zti3yfmZnJ+PHjadKkCTVq1MDPz4/t27c73t+mTZtwdXWlW7duxV4vMjKSvn37Ov795s+fT25uLrfffvtV11rW1AIkUtYc3V/dje0f5OIa94WFj8KR9ZB+1NhtXqondx+jJcas1y6FkSNH8uCDD/LOO+8wa9YsGjRo4PjAf/XVV/n3v//N1KlTadGiBb6+vjz88MPk5eWV+PpLlizhyJEjDB48uMjtVquVZcuWcdNNN+HtffGNgi91H4CLi9G2cW43Xn5+frGP9fUt2jI2fvx4li5dymuvvUbDhg3x9vZm4MCBjvd3udcGuPfee7n77rt58803mTVrFoMHD8bHp/KNhVQLkEhZ26vtL0osIALqnGm237HQ3FqkfFksRjeUGUcp/xAZNGgQLi4ufPbZZ3z00UeMGDECy5lrrFq1iltuuYW77rqLVq1aUb9+fXbt2lWq68+YMYMhQ4awadOmIseQIUMcg6FbtmzJr7/+Wmxw8ff3JyYmhmXLlhV7/Vq1agFw7Ngxx23nDoi+lFWrVjF8+HAGDBhAixYtCA8P58CBA477W7Rogc1mY8WKFRe9Rp8+ffD19WXatGksXryYESNGlOi1K5oCkEhZOnnQmAJvcYV6xTcRy3kK9wbTbDCpJPz8/Bg8eDATJkzg2LFjDB8+3HFfbGwsS5cuZfXq1Wzfvp2///3vJCUllfjaKSkpzJ8/n2HDhtG8efMix9ChQ/n22285ceIEY8aMIT09nSFDhrB+/Xp2797Nxx9/zM6dOwGYNGkSr7/+Om+99Ra7d+9m48aNvP3224DRSnPttdc6BjevWLGCp59+ukT1xcbG8s0337Bp0yY2b97M3/72N0e3HEBMTAzDhg1jxIgRfPvtt+zfv5+ff/6ZL7/80vEYV1dXhg8fzoQJE4iNjaVjx44l/vepSApAImWpsPUnqj141zC1lCqjyZnp8AdWwumT5tYicsbIkSM5efIkPXv2JDLybNfs008/zTXXXEPPnj25/vrrCQ8P59Zbby3xdT/66CN8fX2LHb/TvXt3vL29+eSTTwgODmb58uVkZmbSrVs34uPjef/99x1jgoYNG8bUqVP5v//7P5o1a0a/fv3YvXu341ozZ86koKCA+Ph4Hn74YZ5//vkS1ffGG28QFBREp06d6N+/Pz179uSaa64p8php06YxcOBA/vGPfxAXF8d9991HVlZWkceMHDmSvLw87rnnnhL/21Q0i92udejPl56eTmBgIGlpaQQEBJhdjlQlc+40WjJueBq6PWZ2NVXHO9dCynYY8C60GmJ2NVIGcnJy2L9/P/Xq1cPLy8vscqSC/frrr3Tv3p2EhATCwsLK9NqX+tkqzee3WoBEyoo139gAFTT+p7Qcs8Hmm1uHiFyV3NxcDh8+zKRJk7j99tvLPPyUJQUgkbKSsBbyMsAnGCJam11N1VI4DmjPMsjLNrcWEblin3/+OdHR0Zw6dYpXXnnF7HIuSQFIpKwUjv9pcCO46H+tUoloBYF1oeA07F1udjUicoWGDx+O1Wplw4YN1K5d2+xyLkm/pUXKira/uHIWC8T1Nc41G0xEKoACkEhZyEyGY5uN8wY3mltLVVU4DmjnImM8lVQLmmcjZa2sfqYUgETKwt6fjK/hLcEv1Nxaqqq6HY3xUzmn4OAqs6uRq+Tq6gpQqhWSRUoiO9sYJ1jcNiGloa0wRMqCur+unosrNO4Nv39i7A1W/3qzK5Kr4Obmho+PDykpKbi7uzu2ZxC5Una7nezsbJKTk6lRo4YjZF8pBSCRq2WznbP9hQLQVYnrbwSgHQuh9ysaTF6FWSwWIiIi2L9/PwcPHjS7HKlGatSoQXh4+FVfRwFI5Golbobs4+Dhb6wALVeu/vXg4QcZR+Ho71An3uyK5Cp4eHgQGxurbjApM+7u7lfd8lNIAUjkahV2f9XvBq5X1yft9Ny9jFa0bd/CjvkKQNWAi4uLVoKWSkntyyJXa492fy9ThXuDbdd0eBEpPwpAIlcjJ81YARqggQJQmYi9CVzc4fhuSNlpdjUiUk0pAIlcjX0rwG6F4FgIija7murBK9DoTgTtDSYi5UYBSORqaPp7+SjcG0yrQotIOVEAErlSdvs5438UgMpUXF/AYswESztsdjUiUg0pAIlcqdRdkH4YXD0hupPZ1VQvfqEQ1cE437HQ3FpEpFpSABK5UoXdXzGdwcPH3Fqqo8K9wTQOSETKgQKQyJXS+J/yVTgO6OBqyD5hbi0iUu0oAIlcifzTxgczaPp7ealZD8KaG7Psdi4yuxoRqWYUgESuxIFVUJADAXWgVmOzq6m+NBtMRMqJApDIlXB0f3UHi8XcWqqzwnFAe5dDXpa5tYhItaIAJHIl9mr7iwoR1hxqRButbYWhU0SkDCgAiZTWyYPGFHiLK9TrZnY11ZvFor3BRKRcKACJlFZh609Ue/CuYWopTqFwHNCuJVCQZ24tIlJtKACJlFbh6s+a/VUxotqDby3ITYMDv5pdjYhUEwpAIqVhzTc2QAWN/6koLq7QuI9xrtlgIlJGFIBESiNhLeRlgE8wRLQ2uxrnUTgOaMf3YLOZW4uIVAsKQCKlUTj+p8GN4KL/fSpMva7g4Q+ZiXBkvdnViEg1oN/gIqWh7S/M4eYJjW42zrU3mIiUAQUgkZLKTIZjm43zBjeaW4szOndVaLvd3FpEpMpTABIpqb3Lja/hLcEv1NxanFHsTeDqCSf2QfJ2s6sRkSpOAUikpAqnv6v7yxye/lD/euNcs8FE5CopAImUhM12zvYXCkCmKdwbTOOAROQqKQCJlMSxTZB93JiJFNXe7GqcV+M+YHGBxC3GliQiIldIAUikJApbf+p3A1d3c2txZr4hULejcb5jobm1iEiVpgAkUhJ7tPt7pXHubDARkSukACRyOTlpxgrQoP2/KoO4vsbXQ79BVqq5tYhIlaUAJHI5+1aA3QrBsRAUbXY1EhRtLEVgt8HO782uRkSqKNMD0DvvvENMTAxeXl506NCBtWvXXvLxp06dYvTo0URERODp6UmjRo34/vuivwRLe02RS9Lqz5VPk78YX7erG0xEroypAeiLL75g3LhxTJw4kY0bN9KqVSt69uxJcnJysY/Py8vjpptu4sCBA3z99dfs3LmT999/n9q1a1/xNUUuyW7X+j+VUeF0+H0/QW6GubWISJVksdvNW1O+Q4cOtGvXjv/85z8A2Gw2oqKiePDBB3niiScuePz06dN59dVX2bFjB+7uxc/EKe01i5Oenk5gYCBpaWkEBARc4buTaiFlJ7zT3liB+PED4OFjdkUCRjB9Ox5O7IWBs6D5X82uSEQqgdJ8fpvWApSXl8eGDRvo0ePsX9UuLi706NGD3377rdjnzJs3j44dOzJ69GjCwsJo3rw5L774Ilar9YqvCZCbm0t6enqRQwQ42/0V01nhpzKxWM62Amk2mIhcAdMCUGpqKlarlbCwsCK3h4WFkZiYWOxz9u3bx9dff43VauX777/nmWee4fXXX+f555+/4msCTJkyhcDAQMcRFRV1le9Oqg2N/6m84vobX3f9AAW55tYiIlWO6YOgS8NmsxEaGsp7771HfHw8gwcP5qmnnmL69OlXdd0JEyaQlpbmOBISEsqoYqnS8k/DwdXGuaa/Vz6148EvHPIyYP8vZlcjIlWMaQEoJCQEV1dXkpKSityelJREeHh4sc+JiIigUaNGuLq6Om5r0qQJiYmJ5OXlXdE1ATw9PQkICChyiHBgFRTkQEAdqNXY7GrkfC4uZ9cE0t5gIlJKpgUgDw8P4uPjWbZsmeM2m83GsmXL6NixY7HP6dy5M3v27MFmszlu27VrFxEREXh4eFzRNUUuytH91d0YcyKVT+E4oJ3fg81qbi0iUqWY2gU2btw43n//fT788EO2b9/OAw88QFZWFvfccw8AQ4cOZcKECY7HP/DAA5w4cYKxY8eya9cuFi5cyIsvvsjo0aNLfE2REtur7S8qvZgu4BUIWSlnV+sWESkBNzNffPDgwaSkpPCvf/2LxMREWrduzeLFix2DmA8dOoSLy9mMFhUVxZIlS3jkkUdo2bIltWvXZuzYsTz++OMlvqZIiZw8CKm7wOIK9bqZXY1cjKs7NOoFW74wZoNFq6VXRErG1HWAKiutAySsnwkLHjF2Hh+x2Oxq5FK2zYMv74Ya0TB2s7orRZxYlVgHSKRSK1z9WbO/Kr+G3cHNC04dhKQ/zK5GRKoIBSCR81nzjQ1QQeN/qgIP37NBVXuDiUgJKQCJnC9hrbG2jE8wRLQ2uxopCa0KLSKlZOogaJFKqXD6e4MbjbVmpPJr1MsYsJ70B5zYDzXrmV2RyMX9/gkc2ww1G0BIQwiOhcAo/b6pYApAIufbq93fqxyfmsZ+bft/MVqBOj1odkUixftzLnw3+sLb3bwguKFxhMQaoagwHHlpMk55UAASOVdmsvGXGRgtQFJ1xPU3AtB2BSCppFJ2wrdnwk/szeDqAam74cQ+Y9X5pD+KH8jvF1Y0EIWcOWpEg4vrhY+XElEAEjnX3uXG1/CW4Bdqbi1SOnF9YdFjkPA/I8jqv59UJjnpMOdOyM8yFvAc8jm4nvkIthYYsxiP7zEC0fHdkLrH+JqZdPY4uLLoNV09oGb981qNYo3vfWpW/HusYhSARM61R91fVVZgbYi8Bo5uhB0Loa1Wf5dKwm43ur2O7wb/SBg462z4AeM8uIFxNOpZ9Lk5aWfD0Lnh6MReo9UoZYdxnM8nuGhrUeF5UIyxgKgoAIk42Gwa/1PVNel3JgAtUACSymP127B9Hri4w6CPwK9WyZ/rFQh14o3jXDYbpCUUbS1K3WWcZxyF7OPGkbCm6PNc3IwQdEGXWiMjNDnRQqIKQCKFjm0yfmF4+ENUe7OrkSsR1x+WPWes45STZnx4iJhp/y/w40TjvPdLENWubK7r4gJB0cZx/h9suZlGd1qRLrXdxvf52Wfv23XeNb1qXDgAOyTW6GZz8yybuisRBSCRQoWtP/W7qYm4qqrVyPhLNnUX7F4KLQaaXZE4s7Qj8NU9YLdBqzug7ciKeV1PP4hsbRznstsh/ejZQHRul1paAuScgsPrjONcFheoUdf4f+v8cOQXVmVbjRSARArt0e7v1UJcP1j5BmyfrwAk5inIg6+GQXYqhLWAvm+YHxQsFmOsXGBtqH990fvyT8Pxved1qZ1pNcpNh5MHjGP3D0Wf5xlwZvzSOQOwQxoZt7l7V9AbuzIKQCJgdJckrDXOtf9X1dbkTADa8yPk54C7l9kViTNa8qTRkuIVCIM/Ag8fsyu6NHdvCG9uHOey240ZaOfPTkvdbcxcy02Ho78bRxEWY3HHc1uLCmerBdQ2PwyiACRi2LcC7Fbjf9SgaLOrkasReY3xCzb9COz7GRr3MrsicTabv4B17xvnf33fGENTVVks4B9uHPW6FL2vINdYef2CLrXdRnda2iHjKFxepJC7j9FC1OZu6PD3Cnsr51MAEoGz219o9lfVZ7EYawKtfQ92zFcAkoqV+AfMH2ucd/3nhdPaqxM3TwiNM45z2e3GhJLzB2Cn7oaT+42B2Ilb4fRJc+o+QwFIxG7X+j/VTVw/IwDtXGQsMueqX3VSAU6fgi/ugoLTRlf69U+YXZE5LBbwDTGO6I5F77Pmw8mDxkSF4Abm1HeGfiuIpO6C9MPg6gnRncyuRspCdGfwDjq7DkrMdWZXJNWdzQZz7zdaOALrwm0faJuK4ri6G+OCQhqaXQnaelaksPsrpnPlH6goJePqBo16G+fbF5hbiziHla/DrkXGH1KDP9JWFFWAApCIxv9UT036GV93LDC6OUXKy55lsPwF47zv6xDZxtx6pEQUgMS55Z+Gg6uNc01/r14a3GjMNklLgGObza5GqquTB+G/IwE7XDMMrrnb7IqkhBSAxLkdWGVsKBhQB2o1NrsaKUvu3mcXtdyhbjApB/k58OVQYzZTZBvo/YrZFVVqdrudxLQcVu9N5bP/HWLr4TRT69EgaHFuju6v7pViYS4pY3H9jRWhty+AG582uxqpbhY9Zuwh6F3T2ORUi25it9tJzczjwPEs9qdmcSDV+Lo/NYuDx7M5nW91PPbBGxvSoo55+/UpAIlz26vtL6q1Rjcbu1+nbDeW+Td52q1UIxs+hI0fARYYOMPYK8uJnMrOMwLO8Sz2p2Sx/3g2B84Enozcgos+z9XFQlSQNzEhvkQH+1ZgxRdSABLnVbgWhcUV6nUzuxopD95BENMF9v1ktARd97DZFUl1cGQjfP+YcX7j08Z4s2ooM7eAA6lZ7DsTbA6kZrH/TMvOqez8iz7PYoHIQG/qhfgSE+JDvRA/6oX4EBPsS1RNH9xdK8foGwUgcV6FrT9R7cG7hqmlSDlq0s8IQDsWKADJ1cs+AV8OA2suNO4D140zu6KrcjrPyoHjZ8PN2S6rbFIzcy/53LAAT2KCfalfy5eYYF9iQnypF+JL3Zo+eLlX/jWQFIDEeRWu/qzZX9Vb476w8FFjY8r0YxAQYXZFUlXZrPDfe439rWrWh1ungUvlaM24lNwCKwknstmfml20Red4FsfSci753BA/jyLhJibY19Gy4+NRtSNE1a5e5EpZ840NUEHjf6q7gAio084IQDsXQrt7za5IqqqfXzJajt28YdDHlarluMBq4/DJ00YXVUrW2UHIx7M4cvI0tksshRXg5Ua9Wn7UCza6q4xuKyP0BHi5V9ybqGAKQOKcEtZCXgb4BENEa7OrkfIW188IQNsXKADJldm5GH45M829/78hvHmFl2Cz2Tmadvqc2VXZjqCTcCKbgkukHF8PV0crTmFLTuH3QT7uWJxwFqwCkDinwunvDW6sEk3YcpWa9IcfJ8KBX401W7yDzK5IqpLje+GbUcZ5+1HQanC5vZTdbicpPdfRenNul9XBE9nkFdgu+lxPN5fzws3ZFp1afp5OGXIuRQFInNNe7f7uVIIbQK0mxnT4XT+U6weYVDN52cZih7lpUKc93PzCVV/SbrdzPCuvyBo5RkuOMUbn3LVyzufuaqFuTZ+z43Fq+VLvTOAJD/DCxUUhp6QUgMT5ZCaf3Rqhmk5flWI06WcEoB3zFYCkZOx2WPAwJP0BvrVg0Ifg5nHZp+XkWzl66jTH0nI4cuo0x07lcPTUaY6mGbcdPXWa7LyLhxxXFwt1grwdA44Lx+PUC/YlsoYXbpVkGnlVpwAkzmfvcuNreEvwCzW3Fqk4cf3gl1eN2X/5p42tMkQuZd0HsOULY62wgbMgIBKrzU5yxplAcybYOIJOmnHbiay8y176/LVyzg07dYJ88HBTyClvCkDifPao+8spRbSCwLrGFOa9yyGur9kVSSVjt9s5lZ3P0bTTZO35jfifnsAVmBsyik8Xu3IsbTmJ6TlYLzWl6gwfD1cia3gTEehF7RreRAR6E1nDi8ga3o7bq8JaOdWZApA4F5tN43+clcVihJ7/TTNmgykAOZ3TeVajG+qcLqnzu6pO51sJIY0Fnk/iailgobU9jyRcB5x0XMfNxUJYwJlgUxhqAr3OBBtvatfwJsDbTYOOKzkFIHEuxzZB9nHw8DdWgBbn0qSfEYB2LQJrAbjqV2B1UWC1kZyReybYnOmaOnWaI6dyznRNnebkJbZvKOSKlene/yHcfpJj7nXZ3OoFngoOOSfoeFPL3xNXDTau8vR/vziXwtaf+t3Atfou8CUXUbejsfZT9nE4uMr4OZBKz263czI7/8y4m/NabdJyOHbqNInpOZdc7K+Qb2HXVA1vatfwOtM1dbYFp876Kbit+RM8/Ii472uerNW4/N+gmEIBSJzLHu3+7tRcXKFxb/j9E2NvMAWgSiE7r+CcAcVnWm0KZ02dyuFo2mly8i++/k0hNxcL4YHndUmdF3QCvC7RNbXtO1jztnF+yzug8FOtKQCJ88hJM1aABu3/5czi+hsBaPsC6PWyFsKsICez8tiVlMGu5Ez2JGVw5JzuqUvtLH6uED9PYyBxoDH25vzBxSF+V9E1lbILvh1tnHd6EJrdemXXkSpDAUicx74VYLdCcCwERZtdjZil/vXg4QcZR+Ho71An3uyKqpX0nHx2J2WwKymTnYkZ7E42zlMyLr2zuJ+nG5HFdEkVBp2wgHKcNZWbCV/cZWyPE30ddJ9UPq8jlYoCkDiPwu0vNPvLubl7GT8D2741FkVUALoiWbkF7E7ONFp1Eo2Wnd1JGZfcXbx2DW8ahfnRKMyfqJo+RWZRmbbppt0O88ZA6k7wj4DbZ2lwvJPQf2VxDna71v+Rs5r0NwLQ9gXQY5LZ1VRqOflW9hQGnaTCrxkcPnn6os8JD/Ai9kzQaRzmT2yYH7Fh/vh5VsKPnDX/B3/OBRc3uP1DLY7qRCrhT6NIOUjdBemHwdUTojuZXY2YLfYmcHGH47shZacGuwK5BVb2pWSxKymD3UmZ7EzKYHdSBgdPZGO/yOyqED9PR4uOcRhBJ9C7isywPLAKfnjGOO85Bep2MLceqVAKQOIcCru/YjqDh4+5tYj5vAKNGWB7foTt850qAOVbbRw8nsXORKM1Z3dyBjsTMzhwPPuiKxzX8HF3BByjRccIPDV9L78vVqWVfgy+Gm6MC2wxCNrfZ3ZFUsEUgMQ5aPyPnC+un/FzsWMBdB1vdjVlzmqzc+hEtjEQ+czsq12JGexLzSTfWnzQ8fdycwSdwlad2DA/avl5Vq9VjQvy4KthkJUMoc2g/1RjpXBxKgpAUv3ln4aDq41zTX+XQnF9YcEjxkywtMMQWMfsiq6IzWbnyKnT7EzMYFfyme6rxAz2pmSSW1D82jm+Hq40DPOnUagfjcMLW3T8CA/wql5B52KWPgMJ/wPPQBj8MXj4ml2RmEABSKq/A6ugIAcC6jhVV4dchl8oRHWAhDWwYyF0+LvZFV2S3W7nWFqOYxDyriRj1tXu5Eyy86zFPsfL3YWGoX40CvWnUfiZMTqh/tSu4Y2Ls27lsOUr+N9043zAdAhuYG49YhoFIKn+HN1f3dXMLUU16WcEoO3zK00AstvtpGTkGuvonBmIXDgwOSO3oNjneLi6UL+WrzHrKtyf2NCzU821Z9U5kv6E+Q8Z513GQ1wfc+sRUykASfV3bgASOVdcP/jhaaOLNPsE+NSs0Jc/nplbZGp54eyrtNPFr4zs5mKhXojvBbOuYoJ9cHPVitaXlJNmLHaYnw31b4AbnjS7IjGZApBUbycPGlOdLa5QT/s+yXlq1oOw5pD0B+xcBG3uLJeXycm3sjspk+3H0tl2LN0Yr5OUwfGsvGIf72KBmGBfx1o6hUe9EF883BR0Ss1mg7kPwIl9EBgFt80w9oUTp6YAJNVb4e7vUe3Bu4appUglFdfPCEA7FpRJAErOyGHb0XS2H8tg+7F0th9LZ19qVrFTzC0WiArycbTkFC4a2KCWX/lt++CMVk2FnQvB1QMGfQS+wWZXJJWAApBUb4WrP2v2l1xMk36w4iXYuxzysko8IyjfamNvSuaZkHM27KRmFt+qE+TjTpOIAJpEBBAXbozVaRjqh4+Hfg2Xq70/wfLJxnmfV6H2NebWI5WG/s+T6suab2yAChr/IxcX1hxqRMOpg8Z4saa3XPCQk1l5ju6rwrCzJzmTPOuF08xdLFAvxNcRdpqe+RoWUM3W0qkKTiXAf0eC3QZt7oJrhpldkVQiCkBSfSWsNXZ39gmGiNZmVyOVlcVi7A3223+wbV/AvpDujtacwtadxPTiN/j093QjLsK/SNhpFOaPt4e6r0xXkAtfDoXs4xDRCvq8plmgUoQCkFRfhbO/GtwILho4KkWl5+Sz40xrTnZSEx4AMrcsoPe6fuQX86uxbk0fmpwXduoEeatVp7Ja9Dgc3QjeQTDoY3D3NrsiqWQUgKT62qvd38VYKfnwydNnuq/OHInpJJw4u5u5C4EM9AygliWdru47OB5+3ZmQYwSexuH++HtVkQ0+BX7/BDbMAizw1w8gKNrsiqQSUgCS6ikzGY5tNs4b3GhuLVJhsvMK2JmYUWRQ8o7EDDIvsoBgZKCXo0Xn9LGecOAr3m+fiEv/zhVcuZSZo5tgwTjj/IYnIVZ/AEnxFICketq73Pga3tLY8kCqlcJtIc4dp7P9WDr7j2dhL2afTw9XFxqF+9EkPMAReJpE+FPD55zdzHcPhgNf4bLze+j7urpNq6LsE/Dl3WDNhdiexmrPIhehACTV0x51f1UXuQXGIoLndmHtSMzgVHbxqyWH+HnSJMLfMfuqSUQA9Wv54n65lZLrdQUPf8hMhCPrjbWjpOqw2eCb++DUIQiKgb++qxArl6QAJNWPzabxP1VUSkbuBTOw9qZkUlDMIoJuLhYa1PIrMjC5SUQAtfw9r+zF3Tyh0c3wx3+NvcEUgKqWFS8bEx/cvGDwJ8bgZ5FLUACS6ufYJmPqq4e/PsQqqXyrjX0pWY6gU7i+TmpmbrGPr+Hjfk73lRF4YsP88HQr4+nmcf2MALRjAdz0nKZNVxW7fjACEEC/qRDewtRypGpQAJLqp7D1p343cNXMncogt8DKhoMnWbk7lVV7Utl+LKPYRQQt5ywi2PScsBMe4FUx081jbwJXT2PPqOTtENa0/F9Trs6J/fDNvYAd2t0Lre8wuyKpIhSApPpxjP/R6s9msdvt7EnO5JfdqazcncKafSc4nW8t8hg/Tzfiwv2LDEpuHO5v7tYQnv5Q/3rYvcRoBVIAqtzyTxuDnnPSoE476DnF7IqkCin1b5qYmBhGjBjB8OHDqVu3bnnUJHLlctKMFaBB+39VsNTMXFbtSeXX3an8ujuFpPSi3Vkhfp50iQ2hS2wIbaNrUifIGxeXStjF1KSfEYC2z4du/zS7GrkYu92Y7p64FXxC4PYPwc3j8s8TOaPUAejhhx9m9uzZPPfcc9xwww2MHDmSAQMG4Ol5hQMPRcrSvhVgt0JwrBY/K2c5+VbWHzjJr3tS+HVXKtuOpRe539PNhfb1atI1thbXxYYQF+5fNVZNbtwHLGMhcQucPKifo8pqwyzY/BlYXGDgTAisbXZFUsVY7PbiVs24vI0bNzJ79mw+//xzrFYrf/vb3xgxYgTXXFP1d9pNT08nMDCQtLQ0AgICzC5HSmPeQ7DxQ+jwAPR+yexqqhW73c6OxAxW7k7ll90prN1/gtyCouN4mkYE0KVRCF0a1qJtTBBe7lV0T6xZfeDgKqNLpeM/zK5Gznd4PczsBbZ86PEsXPew2RVJJVGaz+8rXiThmmuu4a233uLo0aNMnDiRDz74gHbt2tG6dWtmzpxJSXPVO++8Q0xMDF5eXnTo0IG1a9de9LGzZ8/GYrEUOby8vIo8JjMzkzFjxlCnTh28vb1p2rQp06dPv9K3KVWJ3a71f8pYckYO32w8zLgvNtH+xWX0/vevvPD9dn7dnUpugY2wAE9uu6YO/x7SmvVP9+D7sV2Y0LsJ18WGVN3wA8ZsMDDGAUnlkpVqbHJqyzf+O3Uea3ZFUkVd8WjD/Px85s6dy6xZs1i6dCnXXnstI0eO5PDhwzz55JP8+OOPfPbZZ5e8xhdffMG4ceOYPn06HTp0YOrUqfTs2ZOdO3cSGlr86r0BAQHs3LnT8f35Terjxo1j+fLlfPLJJ8TExPDDDz/wj3/8g8jISP7yl79c6duVqiB1F6QfNmbxRHcyu5oq6XSelbUHTrBydwq/7k5lR2JGkfu93V3pUL8mXWJr0SU2hNhQv6rRrVVacX1hyQQ49JvxgesbYnZFAmAtgK/vgfQjENwQbp2mpQrkipU6AG3cuJFZs2bx+eef4+LiwtChQ3nzzTeJi4tzPGbAgAG0a9fustd64403uO+++7jnnnsAmD59OgsXLmTmzJk88cQTxT7HYrEQHh5+0WuuXr2aYcOGcf311wMwatQo3n33XdauXasAVN0V7v4e0xk8fMytpYqw2exsO5bOyj3GwOV1B06Sd063lsUCzSMD6RIbwnWxIcRHB5X92juVUVC0sY1K4hbY+T1cM9TsigTgp+dh/y/g7mssduilIQpy5UodgNq1a8dNN93EtGnTuPXWW3F3v3CdlXr16jFkyJBLXicvL48NGzYwYcIEx20uLi706NGD33777aLPy8zMJDo6GpvNxjXXXMOLL75Is2bNHPd36tSJefPmMWLECCIjI/n555/ZtWsXb7755kWvmZubS27u2Rkr6enpF32sVGKFAUjdX5eUmJbDr2daeFbtSeV4Vl6R+yMDvbguNoQusbXo3DCEmr5OOrOmSX8jAG1foABUGWyfDyvP/B6/5W0IbWJuPVLllToA7du3j+joS8+K8PX1ZdasWZd8TGpqKlarlbCwsCK3h4WFsWPHjmKf07hxY2bOnEnLli1JS0vjtddeo1OnTvz555/UqVMHgLfffptRo0ZRp04d3NzccHFx4f3336dr164XrWXKlCk8++yzl6xXKrm8bDiwyjjX9PcisvMK+N++E47p6buTM4vc7+vhyrX1g8+08tSiQS3f6tmtVVpx/eCnF2DfT5CbYawRJOZI3QNzHzDOrx0NzW8ztx6pFkodgJKTk0lMTKRDhw5Fbv/f//6Hq6srbdu2LbPiztexY0c6duzo+L5Tp040adKEd999l8mTJwNGAFqzZg3z5s0jOjqaX375hdGjRxMZGUmPHsW3DEyYMIFx48Y5vk9PTycqKqrc3oeUg4OrjR2gA+pArcZmV2Mqm83OH0fTHIFnw8GT5FvPTkpwsUCLOjXoGhvCdQ1DaFM3CA83bRp5gdAmULO+sSr07qXQ/K9mV+Sc8rLgi7sgLwPqdoKb9MeqlI1SB6DRo0fzz3/+84IAdOTIEV5++WX+97//leg6ISEhuLq6kpSUVOT2pKSkS47xOZe7uztt2rRhz549AJw+fZonn3ySuXPn0rdvXwBatmzJpk2beO211y4agDw9PbWOUVXn6P7q7pSDIo+cOs3K3Sn8sjuV1XtSOXneTum1a3jTtZHRrdWpQTA1fJy0W6s0LBajFWj1W8ZsMAWgime3G0tbpGwHv3C4fba2t5EyU+oAtG3btmLX+mnTpg3btm0r8XU8PDyIj49n2bJl3HrrrQDYbDaWLVvGmDFjSnQNq9XK1q1b6dOnD2DMTMvPz8fFpehfs66urthsF+47JNXIuQHICWTmFrBm73FjLM+eVPalZBW539/TjWsbBButPLG1iAn2UbfWlWjS3whAu36Aglxjx3ipOP97F/74GlzcjPDjH3bZp4iUVKkDkKenJ0lJSdSvX7/I7ceOHcPNrXSXGzduHMOGDaNt27a0b9+eqVOnkpWV5ZgVNnToUGrXrs2UKcb+Ls899xzXXnstDRs25NSpU7z66qscPHiQe++9FzCmyHfr1o3HHnsMb29voqOjWbFiBR999BFvvPFGad+qVBUnD8Lx3WBxhXrdzK6mXFhtdrYcPsXK3cZWExsPnaTAVrRbq3VUDcf09FZRNXB3VbfWVavd1mh5yEw0Zh/F3mR2Rc7j4G/ww1PG+c0vQHTHSz9epJRKHYBuvvlmJkyYwHfffUdgYCAAp06d4sknn+Smm0r3y2Hw4MGkpKTwr3/9i8TERFq3bs3ixYsdA6MPHTpUpDXn5MmT3HfffSQmJhIUFER8fDyrV6+madOzGxbOmTOHCRMmcOedd3LixAmio6N54YUXuP/++0v7VqWqKNz9Pao9eNcwtZSylHAi2zGOZ/Xe46SdLtqtFR3sw3UNjW6tjg2CCfRW10CZc3GBuD6wfqYxC0kBqGJkJMJXw8BWAM0HQoe/m12RVEOl3grjyJEjdO3alePHj9OmTRsANm3aRFhYGEuXLq0Wg4e1FUYVM+dOY4zGDU9Dt8fMruaKpefk89uZbq2Vu1M5cDy7yP0BXm50ahDi2GqibrDWOqoQe5bBJ38F31rw6E5wcYJ1kMxkzYcP/wKHVkOtJnDfMvDwNbsqqSJK8/ld6hag2rVrs2XLFj799FM2b96Mt7c399xzD3fccUexawKJlCtrvrEBKlS58T8FVhubD5/il12prNyTyqaEU1jP6dZyc7HQpq7RrXVdbAgtawfipm6tihfTBTwDISsFEtaqK6a8LZ1ohB8Pf2OxQ4UfKSdXtBWGr68vo0aNKutaREovYa0xPdYnGCJam13NZaVk5LL4z0R+3ZXCb3uPk5FbUOT++iG+jkUIr61fE38v/VFhOjcPaNQTtn5ptDQqAJWfP/4La94xzgdMg5CG5tYj1doV7wW2bds2Dh06RF5e0VVktd2EVKjC2V8NbjTGa1RCVpudX3enMGdtAj9uTyoyeLmGjzudG4Q4tpqoE6RurUqpST8jAG2fDzc/75RLLZS75O3w3YPG+XWPGDPwRMrRFa0EPWDAALZu3YrFYnHs+l44xdZqtZZthSKXsrfy7v5+9NRpvlyfwFfrD3Pk1GnH7a2ianBz0zCuaxhC89qBuLrow7TSa9gD3Lzg1EFI+gPCW5hdUfWSk24sdpifZczkvOFpsysSJ1DqADR27Fjq1avHsmXLqFevHmvXruX48eM8+uijvPbaa+VRo0jxMpPh2GbjvMGN5tZyRr7VxvIdycxZe4gVu1IobOwJ9HZnQJvaDGkfRVy4BtZXOR6+xs/Yzu+NvcEUgMqO3Q7f/QOO74GA2jBwJrheceeESImV+qfst99+Y/ny5YSEhODi4oKLiwvXXXcdU6ZM4aGHHuL3338vjzpFLrR3ufE1vCX4hZpayqHj2cxZd4ivNhwmJePsxrod6tXkjvZ16dU8HC93zR6q0uL6GQFoxwK4YcLlHy8ls/oto2vR1QMGfQy+IWZXJE6i1AHIarXi729sChgSEsLRo0dp3Lgx0dHR7Ny5s8wLFLmoPeZ2f+UWWPnhzyTmrDvEqj3HHbcH+3owML4Og9tFUb+Wnym1STlo3NtYbDPpDzixH2rWM7uiqm/fCvhxknHe+2WoE29qOeJcSh2AmjdvzubNm6lXrx4dOnTglVdewcPDg/fee++C1aFFyo3NZtr4nz3JGcxZm8B/Nx527LllscB1DUO4o31dejQJ0+ai1ZFPTYjuBAd+NVqBOj1odkVVW9oR+HoE2G3Q+k6Iv8fsisTJlDoAPf3002RlGfsOPffcc/Tr148uXboQHBzMF198UeYFihTr2CbIPm6sFRLVvtxf7nSele+3HmPOukOsO3DScXtYgCeD2kYxqG0UUTU1g6vaa9LfCEDbFYCuSkEufDkUslON8VR9X9fMOqlwpQ5APXv2dJw3bNiQHTt2cOLECYKCgrTZolScwtaf+t3KdXfoP4+mMWdtAt9uOkJGjrFmj6uLhRsahzKkXRTXN66lxQmdSVxfWPRPSPifMQjf5LFnVdaSJ+HIevCqYYz7cfc2uyJxQqUKQPn5+Xh7e7Np0yaaN2/uuL1mzZplXpjIJTnG/5T96s+ZuQXM23SUOesOseVwmuP2OkHeDGkXxcD4KMIDvcr8daUKCKwDkW3g6O+wYyG0VbdNqVgLYPlzsO4DwAK3faCxVGKaUgUgd3d36tatq7V+xFw5acYK0AANyiYA2e12NiWcYs7aBOZvOUp2nvEz7u5q4eam4QxpH0XnBiG4aM0eiet3JgAtUAAqjcxkY8zPgV+N77v/S5vLiqlK3QX21FNP8eSTT/Lxxx+r5UfMsW8F2K0QHAtB0Vd1qbTsfOb+fpg56xLYkZjhuL1+iC9D2kfx12vqEOLnebUVS3XSpD8sn2z8HOakgVeg2RVVfofWwJfDIDMRPPzglv9AswFmVyVOrtQB6D//+Q979uwhMjKS6OhofH2LblS3cePGMitOpFiF219c4ewvu93O2v0nmLMuge+3HiO3wAaAp5sLfVpEMKRdFO3r1dSYNilercZG+D6+G3YvhRYDza6o8rLb4X/T4YenwVYAIY2NDU5rNTK7MpHSB6Bbb721HMoQKSG7/YrX/0nNzOW/Gw7zxboE9qVmOW6PC/dnSLsoBrSpQ6CPNh+VEmjSD1a+aSzgpwBUvNxMmPcg/PmN8X2zv8Jf3gZPrY0llUOpA9DEiRPLow6RkknZCemHwdXTWJPlMmw2Oyv3pDJn3SGWbksi32rsTeHj4cpfWkUypH1dWtUJVGuPlE5cfyMA7fkR8nPAXYPii0jZZeztlboTXNzg5hegw9811V0qFW24IlVL4fT3mM7gcfF1dxLTcvhqfQJfrE/g8MlzNiKtE8iQ9nXp3yoSP0/9+MsVimwD/pGQcRT2/QyNe5ldUeXx51z4bgzkZYJ/BNw+G+pea3ZVIhco9SeAi4vLJf9a1gwxKVeXGP9TYLXx884U5qw7xPIdyY6NSP293IyNSNvVpWmkNiKVMuDiYqwJtO592DFfAQjAmg9LJ8Kad4zvY7oYG5tqrSSppEodgObOnVvk+/z8fH7//Xc+/PBDnn322TIrTOQCedlwYJVxfs7094QT2Xy5PoEv1yeQlH52I9J2MUEMaVeXPi0i8PbQRqRSxpr0MwLQzkXG+jbOvIN5+jH4ajgkrDG+7/ww3PiMc/+bSKVX6p/OW2655YLbBg4cSLNmzfjiiy8YOXJkmRQmcoGDq8GaCwF1yAuK5cetx/h87SFW7knFfqa1J8jHnduuqcOQ9lE0DPU3t16p3qI7GysZZx83PvhjrjO7InMcWAlf3QNZyeAZALdOM8KhSCVXZvH82muvZdSoUWV1OZELnen++t0znntfWs7xrDzHXZ0bBjOkXV1ubhaGp5tae6QCuLobO8Rv/tzYG8zZApDdDqvfNnZzt1shtBkM/hiCG5hdmUiJlEkAOn36NG+99Ra1a9cui8uJFJGTb2XRH8dov34+tYF3j9TjuC2PUH9Pbm9bh0Fto4gO9r3sdUTKXFw/IwDtWAC9pjjPLKecdPjuH8YyAAAth0C/Ny85MUGksil1ADp/01O73U5GRgY+Pj588sknZVqcOLcdienMWZvA3N+P4J9zlJWehymwu+Da4Hreu7YJN8aFaiNSMVeDG8HNG9IS4NhmiGxtdkXlL2mbMcX9xF5wcYfeL0Hbkc4T/qTaKHUAevPNN4sEIBcXF2rVqkWHDh0ICgoq0+LE+WTlFrBgy1E+X5vApoRTjtvv9NsOBWCt3Y53Rt5gXoEi5/LwgdgeRkvIjgXVPwBt+RLmj4X8bAioA4M+gjrxZlclckVKHYCGDx9eDmWIM7Pb7Ww9ksbnaxOYv/kombkFALi5WOjRJIwh7aPotvFT2AmejbV5olQycf2NALR9Adz4tNnVlI+CPFjypDHrDaD+DXDbDPANNrcukatQ6gA0a9Ys/Pz8uP3224vc/tVXX5Gdnc2wYcPKrDip3tJz8vnu9yN8vjaBbcfSHbfHBPswuF1dBsbXoZa/p7G+yH9/Me5sWDa7v4uUmUY3G6sdp2yH43ur3yDgtMPGRqZH1hvfd/0nXP8EuGiygVRtpQ5AU6ZM4d13373g9tDQUEaNGqUAJJdkt9vZcPAkn69NYOHWo+TkGxuReri60Kt5OEPaR9GxfnDRxTYT1kJeBvgEQ0RrcwoXuRjvIGPRv30/GS1B1z1sdkVlZ9/P8PUIY6q/VyD89X1o1NPsqkTKRKkD0KFDh6hXr94Ft0dHR3Po0KEyKUqqp4ycfO6ZtY71B086bosN9WNI+7r8tU1tgnw9in9i4erPDW40VuAVqWya9DMC0I4F1SMA2Wyw8g346QWw2yC8pTHFPSjG7MpEykypA1BoaChbtmwhJiamyO2bN28mOFj9wVK8AquNMZ/9zvqDJ/Fyd6F/y0iGtI/imrpBl9+IdO+V7f4uUmEa94WFj8LhdcaqyAERZld05U6fhLkPwK5Fxvdt7oI+r4G7t7l1iZSxUgegO+64g4ceegh/f3+6du0KwIoVKxg7dixDhgwp8wKl6rPb7Tw7fxsrdqXg5e7Cl3/vSMs6NUr25MxkY3oxGC1AIpVRQATUaWcEoJ0Lod29Zld0ZY5tgS/vhpMHwNUT+r4G1ww1uyqRclHqADR58mQOHDhA9+7dcXMznm6z2Rg6dCgvvvhimRcoVd+sVQf4eM1BLBaYOrhNycMPwN7lxtfwltpUUSq3uH5GANq+oGoGoN8/hYXjoCAHatQ1prhHtjG7KpFyU+oA5OHhwRdffMHzzz/Ppk2b8Pb2pkWLFkRHR5dHfVLF/bgtickLtwHwRK84ejUPL90F9qj7S6qIJv3hx4lw4FejG8m7iqyLlp8Di/4JGz80vo+9GQa8Cz41za1LpJxd8VYYsbGxxMbGlmUtUs38eTSNh+b8jt0Od7SPYlTX+qW7gM2m8T9SdQQ3gFpNjOnwu36AVoPNrujyTh6EL4fCsU2ABW54ErqM12QDcQql/im/7bbbePnlly+4/ZVXXrlgbSBxXknpOYycvZ7sPCudGwbz3C3NLz/Y+XzHNhnTbz38Iap9udQpUqYKd0HfMd/cOkpi94/wXjfj/zPvmnDXf6HbPxV+xGmU+if9l19+oU+fPhfc3rt3b3755ZcyKUqqtuy8AkZ+uI7E9Bwa1PLl/+6Mx/1K9uwqbP2p383YeVuksos7E4D2LIP80+bWcjE2G/z8Enw60Oiqi7wG/r5Ci4yK0yn1p1JmZiYeHheu1+Lu7k56enoxzxBnYrXZGTtnE38cSaemrwezhrcn0PsKw4tj/I9+MUsVEdEKAusae2UVDuCvTLJPwGe3w89TADu0HQEjFhuDnkWcTKkDUIsWLfjiiy8uuH3OnDk0bdq0TIqSquvlxTtYui0JDzcX3h8aT91gnyu70OlTxgrQAA0UgKSKsFggrq9xvn2BubWc78hGeLebsbComxfcOh36vQlunmZXJmKKUg+CfuaZZ/jrX//K3r17ufFGY12WZcuW8dlnn/H111+XeYFSdXz2v0O898s+AF4d2JL46KuYRbJ/BditEBwLQZphKFVIk37wv2nGQoLWAnC94rkmZcNuhw2zjZle1jwIqmes6hzewty6RExW6v8z+/fvz7fffsuLL77I119/jbe3N61atWL58uXUrKlpk85q5e5UnvnuDwAe6dGIW1rXvroLavq7VFV1Oxr71mUfh4OrjDFsZsk/baxQvelT4/vGfeHW/wPvGubVJFJJXNFw/759+7Jq1SqysrLYt28fgwYNYvz48bRq1aqs65MqYHdSBg98ugGrzc6ANrV5qHvDq7ug3a4AJFWXiys07m2c7zCxG+zEPvjgJiP8WFygxyQY/InCj8gZVzzf8ZdffmHYsGFERkby+uuvc+ONN7JmzZqyrE2qgNTMXEZ8uI6MnALaxQTx0m0tSj/d/XwpOyH9sLEUf3SnsilUpCLF9Te+7lhoBPqKtnMRvHs9JG0FnxC4+1u47hFNcRc5R6m6wBITE5k9ezYzZswgPT2dQYMGkZuby7fffqsB0E4oJ9/KqI/Wk3DiNHVr+vDu3W3xdHO9+gsXTn+P6QweVziIWsRM9a8HDz9IPwJHN0Lt+Ip5XZvV2MH919eN7+u0h0EfQkBkxby+SBVS4j8H+vfvT+PGjdmyZQtTp07l6NGjvP322+VZm1Ridrudx77ewsZDpwjwcmPm8HbU9L1weYQrsudH46u6v6Sqcvc6+/NbUbPBslLh4wFnw0/7v8PwhQo/IhdR4gC0aNEiRo4cybPPPkvfvn1xdS2Dv/Slynrzx93M33wUNxcL0++Kp2GoX9lcOC8bDqwyzjX9XaqyJoXdYBUQgBLWwbtdjdmT7j5w2wzo8wq4ldEfJSLVUIkD0MqVK8nIyCA+Pp4OHTrwn//8h9TU1PKsTSqpub8f5q1luwF4YUBzOjUMKbuLH1wN1lwIqAO1GpfddUUqWuxN4OIOqbsgZVf5vIbdDmvfh1m9je624Fi4bzm0GFg+rydSjZQ4AF177bW8//77HDt2jL///e/MmTOHyMhIbDYbS5cuJSMjozzrlEpi7f4TPP71VgDu79aAwe3KeAVZR/dXd2NROZGqyivw7BT48tgbLC8LvhkF348HWz40vcUIP6FNyv61RKqhUk8J8PX1ZcSIEaxcuZKtW7fy6KOP8tJLLxEaGspf/vKX8qhRKokDqVmM+ng9eVYbvZuH88+e5dBCc24AEqnqCvcGK+txQKl74P3usPVLsLjCzS/A7R+CV0DZvo5INXZVcyIbN27MK6+8wuHDh/n888/LqiaphE5l5zFi9jpOZefTqk4gbwxqjYtLGbfQnDwIx3cbv9Drmbh4nEhZiesLWIyZYGlHyuaa2+bBe9dDynbwC4PhC6DTGLWYipRSmSwK4erqyq233sq8efPK4nJSyeQV2Lj/kw3sS82idg1v3h/WFm+PchgEXzj9Paq9FmuT6sEvFKI6GOc7Fl7dtawF8MPT8OXdkJcBdTvB33/RWlkiV0irYskl2e12npq7lTX7TuDn6caM4W0J9fcqnxcrXP1Zs7+kOmlyphvsasYBZSTBR3+B1WeWHuk4BobNA//wq69PxEkpAMklTVuxl682HMbFAm//rQ1x4eU0xsCaD/tWGOca/yPVSeE4oAOrIPtE6Z9/8DdjivvBVeDhb4z16fkCuLqXbZ0iTkYBSC7q+63HeGXxTgAm/aUZNzQOLb8XS1hrNOv7BENE6/J7HZGKVrMehDUHuxV2LS758+x2+O0dmN0XMhOhVhyM+gma3VpupYo4EwUgKdamhFM88sUmAIZ3imFox5jyfcHC2V8NbtR+RVL9lHY2WG4GfDUcljxpBKfmA+HeZRASW24lijgbfdLIBQ6fzObeD9eTW2DjxrhQnulXAfu87dXu71KNFY4D2rvMWL/nUpJ3wPs3wrZvwcUNer8Kt30AnmW02rqIAApAcp6MnHxGzl5PamYuceH+vHVHG1zLerr7+TKT4dhm47zBjeX7WiJmCGsONaKhIOfsYP/i/PFfI/yk7gL/SLhnEXQYpSnuIuVAAUgcCqw2xnz2OzuTMqjl78nM4e3w83Qr/xfeu9z4Gt7SmDYsUt1YLJfeG6wgDxY9AV+PgPwsiOliTHGPal+xdYo4EQUgAYzp7s/O38aKXSl4ubswY1hbImt4V8yL71H3lziBwnFAuxYbsx4LpR+FD/vB/6YZ3183Du7+FvxqVXiJIs6kAv68l6pg9uoDfLzmIBYLTB3chpZ1alTMC9tsGv8jziGqPfjWgqwUOPCr0d27/xej1ScrBTwDYcC0M6tHi0h5UwASlm1PYvKCbQA80SuOXs0rcHG1Y5sg+7ixvoma+6U6c3GFxn1g44ewfb4x7m3Zc2C3GWOEBn0EwQ3MrlLEaSgAObltR9N58PPfsdlhSLsoRnWtX7EFFHZ/1e+mhd2k+mvS3whA62cBduO2VndA3zfAw8fU0kScjQKQE0tKz2Hkh+vIzrPSqUEwk29tjqWiZ5s4ur+0+rM4gXpdjdbOvAxw9YDeL0P8PZrlJWICBSAnlZ1XwMgP13EsLYcGtXyZdmc87q4VPCb+9CljBWjQ/l/iHNw84fonYNt30PslqB1vdkUiTksByAlZbXbGztnEH0fSqenrwazh7Qn0MaH7af8KY5Xb4FgIiq741xcxQ6cxxiEiptI0eCf08uIdLN2WhIebC+8PjadusEljDzT9XURETKIA5GQ++98h3vtlHwCvDmxJfHRNcwqx2xWARETENKYHoHfeeYeYmBi8vLzo0KEDa9euvehjZ8+ejcViKXJ4eXld8Ljt27fzl7/8hcDAQHx9fWnXrh2HDh0qz7dRJazcncoz3/0BwCM9GnFL69rmFZOyE9IPg6snRHcyrw4REXFKpgagL774gnHjxjFx4kQ2btxIq1at6NmzJ8nJyRd9TkBAAMeOHXMcBw8eLHL/3r17ue6664iLi+Pnn39my5YtPPPMM8UGJWeyOymDBz7dgNVmZ0Cb2jzUvaG5BRXO/orprOm/IiJS4UwdBP3GG29w3333cc899wAwffp0Fi5cyMyZM3niiSeKfY7FYiE8/OIL9T311FP06dOHV155xXFbgwaXXlwsNzeX3Nxcx/fp6emleRuVXmpmLiM+XEdGTgHtYoJ46bYWFT/d/Xx7fjS+qvtLRERMYFoLUF5eHhs2bKBHj7MfgC4uLvTo0YPffvvtos/LzMwkOjqaqKgobrnlFv7880/HfTabjYULF9KoUSN69uxJaGgoHTp04Ntvv71kLVOmTCEwMNBxREVFXfX7qyxy8q2M+mg9CSdOU7emD+/e3RZPN1dzi8rLhgOrjHNNfxcREROYFoBSU1OxWq2EhYUVuT0sLIzExMRin9O4cWNmzpzJd999xyeffILNZqNTp04cPnwYgOTkZDIzM3nppZfo1asXP/zwAwMGDOCvf/0rK1asuGgtEyZMIC0tzXEkJCSU3Rs1kd1u57Gvt7Dx0CkCvNyYObwdNX09zC4LDq4Gay4E1IFajc2uRkREnFCVWgeoY8eOdOzY0fF9p06daNKkCe+++y6TJ0/GZrMBcMstt/DII48A0Lp1a1avXs306dPp1q1bsdf19PTE09Oz/N9ABXvzx93M33wUNxcL0++Kp2Gon9klGRzdX921Aq6IiJjCtBagkJAQXF1dSUpKKnJ7UlLSJcf4nMvd3Z02bdqwZ88exzXd3Nxo2rRpkcc1adLE6WaBzf39MG8t2w3ACwOa06lhiMkVnePcACQiImIC0wKQh4cH8fHxLFu2zHGbzWZj2bJlRVp5LsVqtbJ161YiIiIc12zXrh07d+4s8rhdu3YRHe08Kw2v3X+Cx7/eCsD93RowuF1dkys6x8mDcHw3WFyhXvEtciIiIuXN1C6wcePGMWzYMNq2bUv79u2ZOnUqWVlZjllhQ4cOpXbt2kyZMgWA5557jmuvvZaGDRty6tQpXn31VQ4ePMi9997ruOZjjz3G4MGD6dq1KzfccAOLFy9m/vz5/Pzzz2a8xQp3IDWLv3+8njyrjV7Nwvlnz0o2xqZw+ntUe/CuYWopIiLivEwNQIMHDyYlJYV//etfJCYm0rp1axYvXuwYGH3o0CFcXM42Up08eZL77ruPxMREgoKCiI+PZ/Xq1UW6vAYMGMD06dOZMmUKDz30EI0bN+a///0v1113XYW/v4qWlp3PiNnrOJmdT8s6gbw5uDUuLpVsjE3h6s+a/SUiIiay2O12u9lFVDbp6ekEBgaSlpZGQECA2eWUSF6BjWEz1/LbvuNEBnrx7ejOhAZUssUfczPg9SaQlwH3/QS1rzG7IhERqUZK8/lt+lYYcvXsdjtPf7uV3/Ydx8/TjRnD21W+8APw80tG+KlZHyJam12NiIg4MQWgamDair18uf4wLhZ4+29taBJRCVutEv+ANdOM896vgot+9ERExDz6FKrivt96jFcWG7PeJv2lGTc0DjW5omLYbLDwUbBboclfIFbbX4iIiLkUgKqwTQmneOSLTQAM7xTD0I4xptZzUZs/h4Q14O4LvaaYXY2IiIgCUFV1+GQ29364ntwCGzfGhfJMv6aXf5IZsk/A0meM8+sfh8A65tYjIiKCAlCVlJGTz8jZ60nNzCUu3J+37miDa2Wb7l5o+WTIPg614uDaf5hdjYiICKAAVOUUWG2M+ex3diZlUMvfk5nD2+HnWUm3dDu8AdbPMs77vgGu7ubWIyIicoYCUBVit9t5dv42VuxKwcvdhRnD2hJZw9vssopns8LCRwA7tBwCMZ3NrkhERMRBAagKmb36AB+vOYjFAlMHt6FlnRpml3Rx62fCsc3gGQg3Tza7GhERkSIUgKqIZduTmLxgGwBP9IqjV/Nwkyu6hMxkWHYm9HR/Bvwq4dR8ERFxagpAVcC2o+k8+Pnv2OwwpF0Uo7rWN7ukS/vhGchNM1Z7bjvC7GpEREQuoABUySWl5zDyw3Vk51np1CCYybc2x2KppDO+AA6shC1zAIsx8NnF1eyKRERELqAAVIll5xVw74frOZaWQ4Navky7Mx5310r8n8yab6z4DND2HqgTb249IiIiF1GJP02dm81m5+E5m9h6JI2avh7MHN6OQJ9KPo18zf9Byg7wCYYbnzG7GhERkYtSAKqkXl68gx+2JeHh6sJ7d8cTHexrdkmXlnYYfn7ZOL9pMvjUNLceERGRS1AAqoQ+X3uId3/ZB8Crt7ekbUwVCBOLJ0B+FtTtCK3uMLsaERGRS1IAqmRW7k7lmW//AOCRHo24pXVtkysqgd0/wvZ5YHGFvq+Di36sRESkctMnVSWyOymDBz7dQIHNzoA2tXmoe0OzS7q8/Bz4frxxfu0DENbM3HpERERKQAGokkjNzGXEh+vIyCmgXUwQL93WonJPdy+0aiqc3A/+EXD9E2ZXIyIiUiIKQJVATr6VUR+tJ+HEaerW9OHdu9vi6VYF1s85sQ9+fcM47/kiePqbW4+IiEgJKQCZzG6389jXW9h46BQBXm7MHN6Omr4eZpd1eXY7fP8YWHOh/g3QbIDZFYmIiJSYApDJ3vxxN/M3H8XNxcL0u+JpGOpndkkls30+7PkRXD2gz2tQFbrrREREzlAAMtHc3w/z1rLdALwwoDmdGoaYXFEJ5WbC4jPjfTqPhZAqMFhbRETkHApAJlm7/wSPf70VgPu7NWBwu7omV1QKv7wC6UegRjR0edTsakREREpNAcgEB1Kz+PvH68mz2ujVLJx/9mxsdkkll7wdfnvHOO/9Crh7m1uPiIjIFVAAqmBp2fmMmL2Ok9n5tKwTyJuDW+PiUkXGz9jtxmantgJo3Bca9zK7IhERkSuiAFSB8gps3P/JBvalZhEZ6MUHQ9vi7VEFprsX2vIlHFwFbt7Q+yWzqxEREbliCkAV6LkFf/LbvuP4ergyY3g7QgO8zC6p5E6fgh+eMs67PQY1qtCYJRERkfMoAFWggfFRhAd48Z+/XUOTiACzyymd5c9DVgqENIKOD5pdjYiIyFVxM7sAZ9I6qgY/P3Y9Xu5VqNsL4OjvsH6Gcd7nNXCrAgs1ioiIXIJagCpYlQs/Npsx8Nlug+YDoX43sysSERG5agpAcmkbP4QjG8DDH3q+YHY1IiIiZUIBSC4uKxV+nGSc3/g0+IebWo6IiEhZUQCSi1s6EXJOQXgLaHev2dWIiIiUGQUgKd6hNbDpE+O87xvgqvHyIiJSfSgAyYWsBbBgnHF+zVCIam9uPSIiImVMAUgutPZdSP4TvIOg+ySzqxERESlzCkBSVPpR+OlF47zHs+AbbG49IiIi5UABSIpa8hTkZUKddtDmbrOrERERKRcKQHLW3p/gz2/A4mIMfHbRj4eIiFRP+oQTQ0EufD/eOG8/CiJamluPiIhIOVIAEsPqt+D4HvALgxueNLsaERGRcqUAJHDyAPzymnF+8wvgFWhqOSIiIuVNAUhg0RNQkAMxXaDFQLOrERERKXcKQM5ux/ewaxG4uEPf18FiMbsiERGRcqcA5MzysmHR48Z5pzFQq7G59YiIiFQQBSBn9utrkHYIAqOg62NmVyMiIlJhFICcVcouWPWWcd7rJfDwNbceERGRCqQA5Izsdvj+UbDlQ2xPiOtrdkUiIiIVSgHIGf3xX9j/C7h5Qe+XNfBZREScjgKQs8lJgyVnFjrs8ijUrGduPSIiIiZQAHI2P02BzCSo2QA6PWR2NSIiIqZQAHImx7bA2neN8z6vgruXufWIiIiYRAHIWdhssPBRsNug6a3QsLvZFYmIiJhGAchZbPoEDq8FDz/oNcXsakREREylAOQMsk/A0onG+fUTICDS3HpERERMpgDkDH6cBKdPQGhT6PB3s6sRERExnQJQdZewDjZ+ZJz3fQNc3c2tR0REpBJQAKrOrAWwcBxgh9Z3QnRHsysSERGpFBSAqrP1MyBxC3gFQo9nza5GRESk0lAAqq4ykmD588Z594ngV8vcekRERCoRBaDq6oenITcdIq+B+OFmVyMiIlKpKABVR/t/ga1fAhbo+zq4uJpdkYiISKWiAFTdFOTBwvHGebuRUPsac+sRERGphCpFAHrnnXeIiYnBy8uLDh06sHbt2os+dvbs2VgsliKHl9fF97S6//77sVgsTJ06tRwqr4TWvAOpO8EnBG582uxqREREKiXTA9AXX3zBuHHjmDhxIhs3bqRVq1b07NmT5OTkiz4nICCAY8eOOY6DBw8W+7i5c+eyZs0aIiOdZOXjUwmw4hXj/ObnwTvI3HpEREQqKdMD0BtvvMF9993HPffcQ9OmTZk+fTo+Pj7MnDnzos+xWCyEh4c7jrCwsAsec+TIER588EE+/fRT3N2dZPG/xU9AfjbU7QSthphdjYiISKVlagDKy8tjw4YN9OjRw3Gbi4sLPXr04Lfffrvo8zIzM4mOjiYqKopbbrmFP//8s8j9NpuNu+++m8cee4xmzZpdto7c3FzS09OLHFXOriWwYwFYXI2BzxaL2RWJiIhUWqYGoNTUVKxW6wUtOGFhYSQmJhb7nMaNGzNz5ky+++47PvnkE2w2G506deLw4cOOx7z88su4ubnx0EMPlaiOKVOmEBgY6DiioqKu/E2ZIf80fP+Ycd7xHxDW1Nx6REREKjnTu8BKq2PHjgwdOpTWrVvTrVs3vvnmG2rVqsW7774LwIYNG/j3v//tGCxdEhMmTCAtLc1xJCQklOdbKHsr34RTB8E/Ero9YXY1IiIilZ6pASgkJARXV1eSkpKK3J6UlER4eHiJruHu7k6bNm3Ys2cPAL/++ivJycnUrVsXNzc33NzcOHjwII8++igxMTHFXsPT05OAgIAiR5VxfK8RgAB6TQFPP3PrERERqQJMDUAeHh7Ex8ezbNkyx202m41ly5bRsWPJNu60Wq1s3bqViIgIAO6++262bNnCpk2bHEdkZCSPPfYYS5YsKZf3YRq7Hb4fD9Y8aNAdmt5idkUiIiJVgpvZBYwbN45hw4bRtm1b2rdvz9SpU8nKyuKee+4BYOjQodSuXZspU6YA8Nxzz3HttdfSsGFDTp06xauvvsrBgwe59957AQgODiY4OLjIa7i7uxMeHk7jxo0r9s2Vt23fwd7l4OoJfV7VwGcREZESMj0ADR48mJSUFP71r3+RmJhI69atWbx4sWNg9KFDh3BxOdtQdfLkSe677z4SExMJCgoiPj6e1atX07Spkw38zc2AxROM8+sehuAGppYjIiJSlVjsdrvd7CIqm/T0dAIDA0lLS6u844GWPAW//QeCYuAfa8Dd2+yKRERETFWaz+8qNwtMgKRtsGaacd7nNYUfERGRUlIAqmrsdlg4DuxWiOsHsTeZXZGIiEiVowBU1Wz+HA79Bu4+0Osls6sRERGpkhSAqpLTJ+GHZ4zzbo9DjSq2YrWIiEgloQBUlSybDNmpENIYrv2H2dWIiIhUWQpAVcWRDbB+pnHe93Vw8zC3HhERkSpMAagqsFlh4aOAHVoOhnpdzK5IRESkSlMAqgo2zIKjv4NnANw02exqREREqjwFoMouMwWWPWec3/gM+IeZW4+IiEg1oABU2S39F+SkQXhLaDfS7GpERESqBQWgyuzgatj8GWCBfm+Ci6vZFYmIiFQLCkCVlTX/zMBnIH4Y1Glrbj0iIiLViAJQZfW/6ZC8DbxrQveJZlcjIiJSrSgAVUZpR+CnKcb5Tc+BT01z6xEREalmFIAqoyVPQn4WRHWA1neaXY2IiEi1owBU2ez5EbZ9CxYXY8VnF/0nEhERKWv6dK1M8nPg+8eM8w73Q3gLc+sRERGpphSAKpPVb8GJfeAXDtdPMLsaERGRaksBqLI4sQ9+ec047/kCeAWYW4+IiEg1pgBUGdjtsOhxsOZCvW7Q/DazKxIREanWFIAqgx0LYfcP4OJuDHy2WMyuSEREpFpTADJbXpbR+gPQ+SEIiTW3HhERESegAGS2Fa9A+mEIrAtdxptdjYiIiFNQADJT8g747T/GeZ9XwMPH3HpERESchAKQWex2+H482AqgUW9o3NvsikRERJyGApBZtn4FB34FN2/o/ZLZ1YiIiDgVBSAz5KTBkqeM867jISjG1HJEREScjQKQGZa/AFnJENwQOj1odjUiIiJORwGooh3dBOveN877vAZunqaWIyIi4owUgCqSzQYLHwW7DZr9FRrcYHZFIiIiTkkBqCL9/hEcWQ8e/tDzRbOrERERcVoKQBUpLxvcvOCGJyEgwuxqREREnJab2QU4lY7/gLi+EFDb7EpEREScmgJQRQuKNrsCERERp6cuMBEREXE6CkAiIiLidBSARERExOkoAImIiIjTUQASERERp6MAJCIiIk5HAUhEREScjgKQiIiIOB0FIBEREXE6CkAiIiLidBSARERExOkoAImIiIjTUQASERERp6Pd4Itht9sBSE9PN7kSERERKanCz+3Cz/FLUQAqRkZGBgBRUVEmVyIiIiKllZGRQWBg4CUfY7GXJCY5GZvNxtGjR/H398disZTptdPT04mKiiIhIYGAgIAyvXZVoPfv3O8f9G/g7O8f9G+g919+799ut5ORkUFkZCQuLpce5aMWoGK4uLhQp06dcn2NgIAAp/zBL6T379zvH/Rv4OzvH/RvoPdfPu//ci0/hTQIWkRERJyOApCIiIg4HQWgCubp6cnEiRPx9PQ0uxRT6P079/sH/Rs4+/sH/Rvo/VeO969B0CIiIuJ01AIkIiIiTkcBSERERJyOApCIiIg4HQUgERERcToKQBXonXfeISYmBi8vLzp06MDatWvNLqnC/PLLL/Tv35/IyEgsFgvffvut2SVVqClTptCuXTv8/f0JDQ3l1ltvZefOnWaXVaGmTZtGy5YtHYufdezYkUWLFpldlmleeuklLBYLDz/8sNmlVIhJkyZhsViKHHFxcWaXVeGOHDnCXXfdRXBwMN7e3rRo0YL169ebXVaFiImJueBnwGKxMHr0aFPqUQCqIF988QXjxo1j4sSJbNy4kVatWtGzZ0+Sk5PNLq1CZGVl0apVK9555x2zSzHFihUrGD16NGvWrGHp0qXk5+dz8803k5WVZXZpFaZOnTq89NJLbNiwgfXr13PjjTdyyy238Oeff5pdWoVbt24d7777Li1btjS7lArVrFkzjh075jhWrlxpdkkV6uTJk3Tu3Bl3d3cWLVrEtm3beP311wkKCjK7tAqxbt26Iv/9ly5dCsDtt99uTkF2qRDt27e3jx492vG91Wq1R0ZG2qdMmWJiVeYA7HPnzjW7DFMlJyfbAfuKFSvMLsVUQUFB9g8++MDsMipURkaGPTY21r506VJ7t27d7GPHjjW7pAoxceJEe6tWrcwuw1SPP/64/brrrjO7jEpj7Nix9gYNGthtNpspr68WoAqQl5fHhg0b6NGjh+M2FxcXevTowW+//WZiZWKWtLQ0AGrWrGlyJeawWq3MmTOHrKwsOnbsaHY5FWr06NH07du3yO8DZ7F7924iIyOpX78+d955J4cOHTK7pAo1b9482rZty+23305oaCht2rTh/fffN7ssU+Tl5fHJJ58wYsSIMt90vKQUgCpAamoqVquVsLCwIreHhYWRmJhoUlViFpvNxsMPP0znzp1p3ry52eVUqK1bt+Ln54enpyf3338/c+fOpWnTpmaXVWHmzJnDxo0bmTJlitmlVLgOHTowe/ZsFi9ezLRp09i/fz9dunQhIyPD7NIqzL59+5g2bRqxsbEsWbKEBx54gIceeogPP/zQ7NIq3LfffsupU6cYPny4aTVoN3iRCjZ69Gj++OMPpxv/ANC4cWM2bdpEWloaX3/9NcOGDWPFihVOEYISEhIYO3YsS5cuxcvLy+xyKlzv3r0d5y1btqRDhw5ER0fz5ZdfMnLkSBMrqzg2m422bdvy4osvAtCmTRv++OMPpk+fzrBhw0yurmLNmDGD3r17ExkZaVoNagGqACEhIbi6upKUlFTk9qSkJMLDw02qSswwZswYFixYwE8//USdOnXMLqfCeXh40LBhQ+Lj45kyZQqtWrXi3//+t9llVYgNGzaQnJzMNddcg5ubG25ubqxYsYK33noLNzc3rFar2SVWqBo1atCoUSP27NljdikVJiIi4oKw36RJE6frCjx48CA//vgj9957r6l1KABVAA8PD+Lj41m2bJnjNpvNxrJly5xu/IOzstvtjBkzhrlz57J8+XLq1atndkmVgs1mIzc31+wyKkT37t3ZunUrmzZtchxt27blzjvvZNOmTbi6uppdYoXKzMxk7969REREmF1KhencufMFy1/s2rWL6Ohokyoyx6xZswgNDaVv376m1qEusAoybtw4hg0bRtu2bWnfvj1Tp04lKyuLe+65x+zSKkRmZmaRv/T279/Ppk2bqFmzJnXr1jWxsooxevRoPvvsM7777jv8/f0dY78CAwPx9vY2ubqKMWHCBHr37k3dunXJyMjgs88+4+eff2bJkiVml1Yh/P39Lxjz5evrS3BwsFOMBRs/fjz9+/cnOjqao0ePMnHiRFxdXbnjjjvMLq3CPPLII3Tq1IkXX3yRQYMGsXbtWt577z3ee+89s0urMDabjVmzZjFs2DDc3EyOIKbMPXNSb7/9tr1u3bp2Dw8Pe/v27e1r1qwxu6QK89NPP9mBC45hw4aZXVqFKO69A/ZZs2aZXVqFGTFihD06Otru4eFhr1Wrlr179+72H374weyyTOVM0+AHDx5sj4iIsHt4eNhr165tHzx4sH3Pnj1ml1Xh5s+fb2/evLnd09PTHhcXZ3/vvffMLqlCLVmyxA7Yd+7caXYpdovdbrebE71EREREzKExQCIiIuJ0FIBERETE6SgAiYiIiNNRABIRERGnowAkIiIiTkcBSERERJyOApCIiIg4HQUgERERcToKQCIiJWCxWPj222/NLkNEyogCkIhUesOHD8disVxw9OrVy+zSRKSK0maoIlIl9OrVi1mzZhW5zdPT06RqRKSqUwuQiFQJnp6ehIeHFzmCgoIAo3tq2rRp9O7dG29vb+rXr8/XX39d5Plbt27lxhtvxNvbm+DgYEaNGkVmZmaRx8ycOZNmzZrh6elJREQEY8aMKXJ/amoqAwYMwMfHh9jYWObNm1e+b1pEyo0CkIhUC8888wy33XYbmzdv5s4772TIkCFs374dgKysLHr27ElQUBDr1q3jq6++4scffywScKZNm8bo0aMZNWoUW7duZd68eTRs2LDIazz77LMMGjSILVu20KdPH+68805OnDhRoe9TRMqI2dvRi4hczrBhw+yurq52X1/fIscLL7xgt9vtdsB+//33F3lOhw4d7A888IDdbrfb33vvPXtQUJA9MzPTcf/ChQvtLi4u9sTERLvdbrdHRkban3rqqYvWANiffvppx/eZmZl2wL5o0aIye58iUnE0BkhEqoQbbriBadOmFbmtZs2ajvOOHTsWua9jx45s2rQJgO3bt9OqVSt8fX0d93fu3BmbzcbOnTuxWCwcPXqU7t27X7KGli1bOs59fX0JCAggOTn5St+SiJhIAUhEqgRfX98LuqTKire3d4ke5+7uXuR7i8WCzWYrj5JEpJxpDJCIVAtr1qy54PsmTZoA0KRJEzZv3kxWVpbj/lWrVuHi4kLjxo3x9/cnJiaGZcuWVWjNImIetQCJSJWQm5tLYmJikdvc3NwICQkB4KuvvqJt27Zcd911fPrpp6xdu5YZM2YAcOeddzJx4kSGDRvGpEmTSElJ4cEHH+Tuu+8mLCwMgEmTJnH//fcTGhpK7969ycjIYNWqVTz44IMV+0ZFpEIoAIlIlbB48WIiIiKK3Na4cWN27NgBGDO05syZwz/+8Q8iIiL4/PPPadq0KQA+Pj4sWbKEsWPH0q5dO3x8fLjtttt44403HNcaNmwYOTk5vPnmm4wfP56QkBAGDhxYcW9QRCqUxW63280uQkTkalgsFubOncutt95qdikiUkVoDJCIiIg4HQUgERERcToaAyQiVZ568kWktNQCJCIiIk5HAUhEREScjgKQiIiIOB0FIBEREXE6CkAiIiLidBSARERExOkoAImIiIjTUQASERERp/P/xhxqCd/AUXYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 13 05:36:46 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   73C    P0             33W /   70W |     653MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   75C    P0             34W /   70W |     117MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "# Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "# Load MobileNetV2 as Base Model\n",
    "base_model = MobileNetV2(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Freeze the base model initially\n",
    "\n",
    "# Define and Compile the Model\n",
    "input_shape = (128, 128, 3)\n",
    "model = models.Sequential([\n",
    "    Input(shape=input_shape),  # Explicitly define input shape\n",
    "    data_augmentation,\n",
    "    base_model,  # MobileNetV2 Base\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Force model to build\n",
    "model.build(input_shape=(None, 128, 128, 3))\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Fine-tune the Model (Unfreeze Last Layers)\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:  # Keep first layers frozen\n",
    "    layer.trainable = False\n",
    "\n",
    "# Train the Model\n",
    "epochs = 8\n",
    "history = model.fit(train_data, epochs=epochs, validation_data=test_data, callbacks=[lr_scheduler])\n",
    "\n",
    "# Evaluate the Model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "if np.isnan(test_loss):  # Fix NaN issue\n",
    "    test_loss = 0.0\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Save the Model\n",
    "model.save(\"object_recognition_model1.keras\")\n",
    "\n",
    "# Extract class labels from dataset info\n",
    "class_names = info.features['objects']['label'].names\n",
    "\n",
    "# Save class labels\n",
    "np.save(\"classes.npy\", class_names)\n",
    "print(\"Class names saved successfully!\")\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Check GPU Usage\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:55:25.268048Z",
     "iopub.status.busy": "2025-03-13T05:55:25.267679Z",
     "iopub.status.idle": "2025-03-13T05:55:26.419850Z",
     "shell.execute_reply": "2025-03-13T05:55:26.419232Z",
     "shell.execute_reply.started": "2025-03-13T05:55:25.268013Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ mobilenetv2_1.00_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,040</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ mobilenetv2_1.00_128 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m655,872\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  │          \u001b[38;5;34m41,040\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,760,886</span> (25.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,760,886\u001b[0m (25.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,902,992</span> (7.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,902,992\u001b[0m (7.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> (4.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,051,904\u001b[0m (4.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,805,990</span> (14.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,805,990\u001b[0m (14.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"object_recognition_model1.keras\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:56:51.197964Z",
     "iopub.status.busy": "2025-03-13T05:56:51.197655Z",
     "iopub.status.idle": "2025-03-13T05:56:55.556357Z",
     "shell.execute_reply": "2025-03-13T05:56:55.555652Z",
     "shell.execute_reply.started": "2025-03-13T05:56:51.197940Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "[[1.315e-01 6.958e-03 2.211e-02 9.041e-04 1.953e-02 2.520e-03 1.904e-02\n",
      "  1.672e-02 7.422e-02 8.186e-03 5.428e-03 1.755e-03 1.415e-03 6.879e-02\n",
      "  2.468e-01 9.521e-03 2.415e-02 3.149e-02 3.094e-02 3.217e-02 1.065e-02\n",
      "  7.011e-03 3.476e-02 1.019e-01 1.061e-02 1.961e-02 8.850e-03 2.083e-03\n",
      "  3.223e-03 4.772e-03 1.727e-03 2.693e-03 1.938e-02 6.958e-03 3.593e-03\n",
      "  3.260e-03 2.201e-03 1.065e-02 7.320e-03 7.576e-03 4.480e-04 2.823e-03\n",
      "  2.149e-04 6.957e-04 3.202e-04 1.995e-03 1.629e-03 1.367e-03 5.394e-05\n",
      "  6.852e-04 1.911e-04 3.126e-04 5.305e-05 3.710e-04 1.442e-04 3.004e-04\n",
      "  1.810e-02 1.315e-03 9.193e-03 5.775e-03 3.147e-03 4.200e-03 1.861e-03\n",
      "  1.543e-03 6.142e-04 9.661e-04 9.327e-04 4.417e-03 6.905e-04 1.250e-03\n",
      "  8.482e-05 1.949e-03 9.851e-04 4.070e-03 4.272e-02 3.336e-03 2.510e-03\n",
      "  1.461e-03 1.432e-04 4.480e-04]]\n"
     ]
    }
   ],
   "source": [
    "sample_input = np.random.rand(1, 128, 128, 3)  # Random input of shape (1, 128, 128, 3)\n",
    "predictions = model.predict(sample_input)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:57:43.308419Z",
     "iopub.status.busy": "2025-03-13T05:57:43.308108Z",
     "iopub.status.idle": "2025-03-13T05:57:43.958465Z",
     "shell.execute_reply": "2025-03-13T05:57:43.957743Z",
     "shell.execute_reply.started": "2025-03-13T05:57:43.308394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save(\"object_recognition_model1.keras\", save_format=\"keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:57:49.740962Z",
     "iopub.status.busy": "2025-03-13T05:57:49.740656Z",
     "iopub.status.idle": "2025-03-13T05:57:49.763163Z",
     "shell.execute_reply": "2025-03-13T05:57:49.762280Z",
     "shell.execute_reply.started": "2025-03-13T05:57:49.740938Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ mobilenetv2_1.00_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,040</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ mobilenetv2_1.00_128 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m655,872\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  │          \u001b[38;5;34m41,040\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,760,886</span> (25.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,760,886\u001b[0m (25.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,902,992</span> (7.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,902,992\u001b[0m (7.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> (4.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,051,904\u001b[0m (4.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,805,990</span> (14.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,805,990\u001b[0m (14.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T19:22:33.103559Z",
     "iopub.status.busy": "2025-03-15T19:22:33.103351Z",
     "iopub.status.idle": "2025-03-15T19:59:15.889724Z",
     "shell.execute_reply": "2025-03-15T19:59:15.881556Z",
     "shell.execute_reply.started": "2025-03-15T19:22:33.103538Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset 25.20 GiB (download: 25.20 GiB, generated: Unknown size, total: 25.20 GiB) to /root/tensorflow_datasets/coco/2017/1.1.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541cafdafbed44418e6a9f534828023c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba210b54b7af4d4c8a0014ab479edc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f96bb9e428e452cbd2858ce94ba2a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/118287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /root/tensorflow_datasets/coco/2017/incomplete.JQM5T3_1.1.0/coco-train.tfrecord*...:   0%|          …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation examples...:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /root/tensorflow_datasets/coco/2017/incomplete.JQM5T3_1.1.0/coco-validation.tfrecord*...:   0%|     …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/40670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /root/tensorflow_datasets/coco/2017/incomplete.JQM5T3_1.1.0/coco-test.tfrecord*...:   0%|          |…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset coco downloaded and prepared to /root/tensorflow_datasets/coco/2017/1.1.0. Subsequent calls will reuse this data.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ mobilenetv2_1.00_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,040</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ mobilenetv2_1.00_128 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m655,872\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  │          \u001b[38;5;34m41,040\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,954,896</span> (11.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,954,896\u001b[0m (11.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,920,784</span> (11.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,920,784\u001b[0m (11.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,112</span> (133.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,112\u001b[0m (133.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.4459 - loss: 71.2233\n",
      "Epoch 1: val_accuracy improved from -inf to 0.01600, saving model to object_recognition_model_best.keras\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 134ms/step - accuracy: 0.4460 - loss: 71.5316 - val_accuracy: 0.0160 - val_loss: 22.2245 - learning_rate: 1.0000e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.4846 - loss: 713.3376\n",
      "Epoch 2: val_accuracy improved from 0.01600 to 0.54400, saving model to object_recognition_model_best.keras\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 126ms/step - accuracy: 0.4846 - loss: 713.9707 - val_accuracy: 0.5440 - val_loss: 36.2243 - learning_rate: 1.0000e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.4801 - loss: 1695.8978\n",
      "Epoch 3: val_accuracy did not improve from 0.54400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 124ms/step - accuracy: 0.4801 - loss: 1696.7156 - val_accuracy: 0.5440 - val_loss: 65.8026 - learning_rate: 1.0000e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.4767 - loss: 2837.4663\n",
      "Epoch 4: val_accuracy did not improve from 0.54400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 127ms/step - accuracy: 0.4767 - loss: 2838.0884 - val_accuracy: 0.5440 - val_loss: 86.5664 - learning_rate: 5.0000e-05\n",
      "Epoch 5/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.4845 - loss: 3642.3457\n",
      "Epoch 5: val_accuracy did not improve from 0.54400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 125ms/step - accuracy: 0.4845 - loss: 3642.9634 - val_accuracy: 0.5440 - val_loss: 110.3960 - learning_rate: 5.0000e-05\n",
      "Epoch 6/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.4794 - loss: 4377.9814\n",
      "Epoch 6: val_accuracy did not improve from 0.54400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 125ms/step - accuracy: 0.4794 - loss: 4378.3994 - val_accuracy: 0.5440 - val_loss: 123.2719 - learning_rate: 2.5000e-05\n",
      "Epoch 7/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.4810 - loss: 4793.8311\n",
      "Epoch 7: val_accuracy did not improve from 0.54400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 126ms/step - accuracy: 0.4810 - loss: 4794.2119 - val_accuracy: 0.5440 - val_loss: 139.2002 - learning_rate: 2.5000e-05\n",
      "Epoch 8/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.4786 - loss: 5135.6021\n",
      "Epoch 8: val_accuracy did not improve from 0.54400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 126ms/step - accuracy: 0.4786 - loss: 5135.9634 - val_accuracy: 0.5440 - val_loss: 220.0023 - learning_rate: 1.2500e-05\n",
      "Epoch 9/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.4809 - loss: 5430.6470\n",
      "Epoch 9: val_accuracy did not improve from 0.54400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 127ms/step - accuracy: 0.4809 - loss: 5430.9570 - val_accuracy: 0.5440 - val_loss: 300.1889 - learning_rate: 1.2500e-05\n",
      "Epoch 10/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.4771 - loss: 5763.5820\n",
      "Epoch 10: val_accuracy did not improve from 0.54400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 127ms/step - accuracy: 0.4771 - loss: 5763.6260 - val_accuracy: 0.5440 - val_loss: 378.1085 - learning_rate: 6.2500e-06\n",
      "Epoch 11/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.4761 - loss: 5724.3325\n",
      "Epoch 11: val_accuracy did not improve from 0.54400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 125ms/step - accuracy: 0.4761 - loss: 5724.6665 - val_accuracy: 0.5440 - val_loss: 435.0414 - learning_rate: 6.2500e-06\n",
      "Epoch 12/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.4708 - loss: 5868.7222\n",
      "Epoch 12: val_accuracy did not improve from 0.54400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 125ms/step - accuracy: 0.4708 - loss: 5868.8955 - val_accuracy: 0.5440 - val_loss: 496.5605 - learning_rate: 3.1250e-06\n",
      "Epoch 13/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.4855 - loss: 5897.5225\n",
      "Epoch 13: val_accuracy did not improve from 0.54400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 128ms/step - accuracy: 0.4855 - loss: 5897.7471 - val_accuracy: 0.5440 - val_loss: 543.8583 - learning_rate: 3.1250e-06\n",
      "Epoch 14/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.4785 - loss: 5930.7168\n",
      "Epoch 14: val_accuracy did not improve from 0.54400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 125ms/step - accuracy: 0.4785 - loss: 5930.8774 - val_accuracy: 0.5440 - val_loss: 615.3441 - learning_rate: 1.5625e-06\n",
      "Epoch 15/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.4816 - loss: 5972.2378\n",
      "Epoch 15: val_accuracy did not improve from 0.54400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 126ms/step - accuracy: 0.4816 - loss: 5972.3579 - val_accuracy: 0.5440 - val_loss: 646.4862 - learning_rate: 1.5625e-06\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5511 - loss: 484.3846\n",
      "Test Accuracy: 54.40%\n",
      "Test Loss: 646.4862\n",
      "Class names saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Load the COCO dataset\n",
    "datasets, info = tfds.load('coco/2017', with_info=True, split=['train[:10%]', 'validation[:10%]'])\n",
    "train_data, val_data = datasets\n",
    "\n",
    "# Define num_classes\n",
    "num_classes = info.features['objects']['label'].num_classes  # COCO has 80 classes\n",
    "\n",
    "# Data Preprocessing Function\n",
    "def preprocess_data(data):\n",
    "    image = tf.image.resize(data['image'], (128, 128))  # Resize to 128x128\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize\n",
    "\n",
    "    # Ensure no NaN or Inf values in the image\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "\n",
    "    # Extract labels from the 'objects' field\n",
    "    labels = data['objects']['label']\n",
    "    labels = tf.one_hot(labels, depth=num_classes)  # One-hot encode labels\n",
    "    labels = tf.reduce_max(labels, axis=0)  # Convert to multi-hot encoding\n",
    "\n",
    "    # Ensure no NaN or Inf values in the labels\n",
    "    labels = tf.clip_by_value(labels, 0.0, 1.0)\n",
    "\n",
    "    return image, labels\n",
    "\n",
    "# Preprocess and batch the data\n",
    "batch_size = 32\n",
    "train_data = train_data.map(preprocess_data).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_data = val_data.map(preprocess_data).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "# Load MobileNetV2 as Base Model\n",
    "base_model = MobileNetV2(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = True  # Fine-tune the base model\n",
    "\n",
    "# Define and compile the model\n",
    "input_shape = (128, 128, 3)\n",
    "model = models.Sequential([\n",
    "    Input(shape=input_shape),  # Explicitly define input shape\n",
    "    data_augmentation,\n",
    "    base_model,  # MobileNetV2 Base\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')  # Use softmax for multi-class classification\n",
    "])\n",
    "\n",
    "# Force model to build\n",
    "model.build(input_shape=(None, 128, 128, 3))\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Model Checkpoint to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"object_recognition_model_best.keras\",\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001, clipvalue=1.0),  # Reduced learning rate with gradient clipping\n",
    "    loss='categorical_crossentropy',  # Correct loss function\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "# Train the model\n",
    "epochs = 15  # Increase the number of epochs\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data,\n",
    "    callbacks=[lr_scheduler, checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(val_data)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Save the final model\n",
    "# Save the entire model in TensorFlow SavedModel format\n",
    "model.save(\"object_recognition_model_final.keras\", save_format=\"tf\")\n",
    "\n",
    "# Save class labels\n",
    "class_names = info.features['objects']['label'].names  # Replace with actual class names\n",
    "np.save(\"classes.npy\", class_names)\n",
    "print(\"Class names saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(\"kaggle/working/object_recognition_model_final.keras\")\n",
    "\n",
    "# Load class names\n",
    "class_names = np.load(\"kaggle/working/classes.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Predict on a single test image\n",
    "sample_image = X_test[0].reshape(1, 128, 128, 3)  # Reshape depending on your input size\n",
    "prediction = model.predict(sample_image)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = class_names[np.argmax(prediction)]\n",
    "print(f\"Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T16:09:07.150455Z",
     "iopub.status.busy": "2025-03-14T16:09:07.150131Z",
     "iopub.status.idle": "2025-03-14T16:21:55.392006Z",
     "shell.execute_reply": "2025-03-14T16:21:55.391107Z",
     "shell.execute_reply.started": "2025-03-14T16:09:07.150431Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.2579 - loss: 5.3995\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55800, saving model to object_recognition_model_best.keras\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 130ms/step - accuracy: 0.2582 - loss: 5.3947 - val_accuracy: 0.5580 - val_loss: 1.1720 - learning_rate: 1.0000e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5182 - loss: 0.7825\n",
      "Epoch 2: val_accuracy improved from 0.55800 to 0.57000, saving model to object_recognition_model_best.keras\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 127ms/step - accuracy: 0.5182 - loss: 0.7818 - val_accuracy: 0.5700 - val_loss: 0.2196 - learning_rate: 1.0000e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5488 - loss: 0.1719\n",
      "Epoch 3: val_accuracy improved from 0.57000 to 0.58600, saving model to object_recognition_model_best.keras\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 128ms/step - accuracy: 0.5487 - loss: 0.1718 - val_accuracy: 0.5860 - val_loss: 0.1334 - learning_rate: 1.0000e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5571 - loss: 0.1180\n",
      "Epoch 4: val_accuracy did not improve from 0.58600\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 126ms/step - accuracy: 0.5571 - loss: 0.1180 - val_accuracy: 0.5860 - val_loss: 0.1226 - learning_rate: 1.0000e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5704 - loss: 0.1114\n",
      "Epoch 5: val_accuracy did not improve from 0.58600\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 125ms/step - accuracy: 0.5704 - loss: 0.1114 - val_accuracy: 0.5840 - val_loss: 0.1243 - learning_rate: 1.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5748 - loss: 0.1080\n",
      "Epoch 6: val_accuracy did not improve from 0.58600\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 127ms/step - accuracy: 0.5748 - loss: 0.1080 - val_accuracy: 0.5820 - val_loss: 0.1198 - learning_rate: 1.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5834 - loss: 0.1052\n",
      "Epoch 7: val_accuracy improved from 0.58600 to 0.60000, saving model to object_recognition_model_best.keras\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 127ms/step - accuracy: 0.5834 - loss: 0.1052 - val_accuracy: 0.6000 - val_loss: 0.1311 - learning_rate: 1.0000e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5960 - loss: 0.1029\n",
      "Epoch 8: val_accuracy did not improve from 0.60000\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 126ms/step - accuracy: 0.5960 - loss: 0.1029 - val_accuracy: 0.5860 - val_loss: 0.1279 - learning_rate: 1.0000e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.6011 - loss: 0.0993\n",
      "Epoch 9: val_accuracy improved from 0.60000 to 0.61400, saving model to object_recognition_model_best.keras\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 127ms/step - accuracy: 0.6011 - loss: 0.0993 - val_accuracy: 0.6140 - val_loss: 0.1143 - learning_rate: 5.0000e-05\n",
      "Epoch 10/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.6109 - loss: 0.0964\n",
      "Epoch 10: val_accuracy did not improve from 0.61400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 126ms/step - accuracy: 0.6109 - loss: 0.0964 - val_accuracy: 0.5900 - val_loss: 0.1136 - learning_rate: 5.0000e-05\n",
      "Epoch 11/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.6135 - loss: 0.0953\n",
      "Epoch 11: val_accuracy did not improve from 0.61400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 126ms/step - accuracy: 0.6135 - loss: 0.0953 - val_accuracy: 0.6020 - val_loss: 0.1128 - learning_rate: 5.0000e-05\n",
      "Epoch 12/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.6151 - loss: 0.0945\n",
      "Epoch 12: val_accuracy did not improve from 0.61400\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 125ms/step - accuracy: 0.6151 - loss: 0.0945 - val_accuracy: 0.6100 - val_loss: 0.1104 - learning_rate: 5.0000e-05\n",
      "Epoch 13/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.6144 - loss: 0.0929\n",
      "Epoch 13: val_accuracy improved from 0.61400 to 0.62000, saving model to object_recognition_model_best.keras\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 129ms/step - accuracy: 0.6144 - loss: 0.0929 - val_accuracy: 0.6200 - val_loss: 0.1134 - learning_rate: 5.0000e-05\n",
      "Epoch 14/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.6269 - loss: 0.0914\n",
      "Epoch 14: val_accuracy did not improve from 0.62000\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 125ms/step - accuracy: 0.6269 - loss: 0.0914 - val_accuracy: 0.6080 - val_loss: 0.1112 - learning_rate: 5.0000e-05\n",
      "Epoch 15/15\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.6177 - loss: 0.0898\n",
      "Epoch 15: val_accuracy did not improve from 0.62000\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 126ms/step - accuracy: 0.6177 - loss: 0.0898 - val_accuracy: 0.6060 - val_loss: 0.1030 - learning_rate: 2.5000e-05\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5991 - loss: 0.1051\n",
      "Test Accuracy: 60.60%\n",
      "Test Loss: 0.1030\n",
      "Class names saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Load the COCO dataset\n",
    "datasets, info = tfds.load('coco/2017', with_info=True, split=['train[:10%]', 'validation[:10%]'])\n",
    "train_data, val_data = datasets\n",
    "\n",
    "# Define num_classes\n",
    "num_classes = info.features['objects']['label'].num_classes  # COCO has 80 classes\n",
    "\n",
    "# Data Preprocessing Function\n",
    "def preprocess_data(data):\n",
    "    image = tf.image.resize(data['image'], (128, 128))  # Resize to 128x128\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize\n",
    "\n",
    "    # Extract labels from the 'objects' field\n",
    "    labels = data['objects']['label']\n",
    "    labels = tf.reduce_sum(tf.one_hot(labels, depth=num_classes), axis=0)  # Multi-hot encoding\n",
    "    labels = tf.cast(labels > 0, tf.float32)  # Convert to binary vector\n",
    "\n",
    "    return image, labels\n",
    "\n",
    "# Preprocess and batch the data\n",
    "batch_size = 32\n",
    "train_data = train_data.map(preprocess_data).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_data = val_data.map(preprocess_data).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "# Load MobileNetV2 as Base Model\n",
    "base_model = MobileNetV2(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = True  # Fine-tune the base model\n",
    "\n",
    "# Define and compile the model\n",
    "input_shape = (128, 128, 3)\n",
    "model = models.Sequential([\n",
    "    Input(shape=input_shape),  # Explicitly define input shape\n",
    "    data_augmentation,\n",
    "    base_model,  # MobileNetV2 Base\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='sigmoid')  # Use sigmoid for multi-label classification\n",
    "])\n",
    "\n",
    "# Force model to build\n",
    "model.build(input_shape=(None, 128, 128, 3))\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Model Checkpoint to save the best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"object_recognition_model_best.keras\",\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001, clipvalue=1.0),  # Reduced learning rate with gradient clipping\n",
    "    loss='binary_crossentropy',  # Use binary_crossentropy for multi-label classification\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "epochs = 15  # Increase the number of epochs\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data,\n",
    "    callbacks=[lr_scheduler, checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(val_data)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Save the final model\n",
    "model.save(\"object_recognition_model__final.keras\")\n",
    "\n",
    "# Save class labels\n",
    "class_names = info.features['objects']['label'].names  # Replace with actual class names\n",
    "np.save(\"classes.npy\", class_names)\n",
    "print(\"Class names saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
